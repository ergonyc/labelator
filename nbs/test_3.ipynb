{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import dask.dataframe as dd\n",
    "# import dask.array as da\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import mmwrite\n",
    "\n",
    "\n",
    "# File paths\n",
    "obs_file_path = \"cell_barcde_labels.csv\"\n",
    "count_matrix_file_path = \"brain_atlas_full_counts_table.csv\"\n",
    "\n",
    "# Paths\n",
    "obs_file_path = \"./data/cell_barcode_labels.csv\"\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "h5ad_file_path = \"./data/dask_output_data.h5ad\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify a larger sample size (e.g., 1e7 bytes)\n",
    "sample_size = 1e7\n",
    "\n",
    "\n",
    "cells = pd.read_csv(obs_file_path,index_col=0)\n",
    "\n",
    "\n",
    "# Specify data types\n",
    "# Assuming that the first column is object (like string) and the rest are uint8.\n",
    "dtypes = {0: 'object'}\n",
    "for col in range(1, 713626):  # Adjust the range based on the number of columns\n",
    "    dtypes[col] = 'uint8'\n",
    "\n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number 0\n",
      "chunk number 1\n",
      "chunk number 2\n",
      "chunk number 3\n",
      "chunk number 4\n",
      "chunk number 5\n",
      "chunk number 6\n",
      "chunk number 7\n",
      "chunk number 8\n",
      "chunk number 9\n",
      "matrix shape (713626, 100) \n",
      " var shape (100, 1) obs shape 713626\n",
      "wrote (100, 1) genes to adata file ./data/chunk20009_output_data.h5ad\n",
      "chunk number 10\n",
      "chunk number 11\n",
      "chunk number 12\n",
      "chunk number 13\n",
      "chunk number 14\n",
      "chunk number 15\n",
      "chunk number 16\n",
      "chunk number 17\n",
      "chunk number 18\n",
      "chunk number 19\n",
      "matrix shape (713626, 100) \n",
      " var shape (100, 1) obs shape 713626\n",
      "wrote (100, 1) genes to adata file ./data/chunk20019_output_data.h5ad\n",
      "chunk number 20\n",
      "chunk number 21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 1. Read the CSV in chunks using a context manager\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(count_matrix_file_path, header\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,dtype\u001b[39m=\u001b[39mdtypes, chunksize\u001b[39m=\u001b[39mchunk_size) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchunk number \u001b[39m\u001b[39m{\u001b[39;00mchunk_counter\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_3.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m# 2. get the genes\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1624\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   1623\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[1;32m   1625\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1626\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1733\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[0;32m-> 1733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:389\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    387\u001b[0m     result[name] \u001b[39m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     result[name] \u001b[39m=\u001b[39m concat_compat(arrs)\n\u001b[1;32m    390\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(non_cat_dtypes) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m result[name]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    391\u001b[0m         warning_columns\u001b[39m.\u001b[39mappend(\u001b[39mstr\u001b[39m(name))\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/dtypes/concat.py:79\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     77\u001b[0m all_empty \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(non_empties)\n\u001b[1;32m     78\u001b[0m single_dtype \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m({x\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat}) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 79\u001b[0m any_ea \u001b[39m=\u001b[39m \u001b[39many\u001b[39;49m(\u001b[39misinstance\u001b[39;49m(x\u001b[39m.\u001b[39;49mdtype, ExtensionDtype) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m contains_datetime:\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m _concat_datetime(to_concat, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/dtypes/concat.py:79\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m all_empty \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(non_empties)\n\u001b[1;32m     78\u001b[0m single_dtype \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m({x\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat}) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 79\u001b[0m any_ea \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39;49m(x\u001b[39m.\u001b[39;49mdtype, ExtensionDtype) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m contains_datetime:\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m _concat_datetime(to_concat, axis\u001b[39m=\u001b[39maxis)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10  # \n",
    "\n",
    "# Create an empty list to store sparse matrices from each chunk\n",
    "chunk_counter = 0\n",
    "sparse_matrices = []\n",
    "genes = []\n",
    "# 1. Read the CSV in chunks using a context manager\n",
    "with pd.read_csv(count_matrix_file_path, header=0,dtype=dtypes, chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "\n",
    "        print(f\"chunk number {chunk_counter}\")\n",
    "        # 2. get the genes\n",
    "        gene_chunk = chunk['genes']\n",
    "\n",
    "        sparse_chunk = csr_matrix(chunk.iloc[:,1:].values.T)\n",
    "        genes.append(gene_chunk)\n",
    "        sparse_matrices.append(sparse_chunk)\n",
    "\n",
    "        # after each 10 chunks write file and reset\n",
    "        if (chunk_counter+1) % 10 == 0:\n",
    "            sparse_matrix = hstack(sparse_matrices)\n",
    "            genes_ = pd.DataFrame(index = pd.concat(genes, axis=0))\n",
    "            genes_['chunk'] = chunk_counter\n",
    "\n",
    "            # adata_dict = {}\n",
    "            # adata_dict[\"X\"] = sparse_matrix.transpose()\n",
    "            # adata_dict[\"obs\"] = cells\n",
    "            # adata_dict[\"var\"] = genes_\n",
    "            # # adata_dict[\"dtype\"] = np.float64\n",
    "            # # adata_dict[\"obsm\"] = dict(\n",
    "            # #     a=da.random.random((M, 100)),\n",
    "            # # )\n",
    "            # # adata_dict[\"layers\"] = dict(\n",
    "            # #     a=da.random.random((M, N)),\n",
    "            # # )\n",
    "            print(f\"matrix shape {sparse_matrix.shape} \\n var shape {genes_.shape} obs shape {cells.shape[0]}\")\n",
    "\n",
    " \n",
    "            adata = ad.AnnData(X=sparse_matrix, obs=cells, var=genes_)\n",
    "            # adata = ad.AnnData(**adata_dict)\n",
    "            h5ad_file_path = f\"./data/chunk2{chunk_counter+1:04d}_output_data.h5ad\"\n",
    "            adata.write_h5ad(h5ad_file_path)\n",
    "            del adata\n",
    "            print(f\"wrote {genes_.shape} genes to adata file {h5ad_file_path}\")\n",
    "            sparse_matrices = []\n",
    "            genes = []\n",
    "\n",
    "        chunk_counter += 1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkv = chunk.iloc[:,1:].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(X=sparse_matrix.transpose(), obs=cells, var=genes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = vstack(sparse_matrices)\n",
    "genes_ = pd.DataFrame(index = pd.concat(genes, axis=0))\n",
    "\n",
    "adata_dict = {}\n",
    "adata_dict[\"X\"] = sparse_matrix.transpose()\n",
    "adata_dict[\"obs\"] = cells\n",
    "adata_dict[\"var\"] = genes_\n",
    "\n",
    "adata = ad.AnnData(**adata_dict)\n",
    "h5ad_file_path = f\"./data/chunk{chunk_counter+1:04d}_output_data.h5ad\"\n",
    "adata.write_h5ad(h5ad_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MIR1302-2HG', 'FAM138A', 'OR4F5', 'AL627309.1', 'AL627309.3',\n",
       "       'AL627309.2', 'AL627309.5', 'AL627309.4', 'AP006222.2', 'AL732372.1',\n",
       "       'OR4F29', 'AC114498.1', 'OR4F16', 'AL669831.2', 'LINC01409', 'FAM87B',\n",
       "       'LINC01128', 'LINC00115', 'FAM41C', 'AL645608.6', 'AL645608.2',\n",
       "       'AL645608.4', 'LINC02593', 'SAMD11', 'NOC2L', 'KLHL17', 'PLEKHN1',\n",
       "       'PERM1', 'AL645608.7', 'HES4', 'ISG15', 'AL645608.1', 'AGRN',\n",
       "       'AL645608.5', 'AL645608.8', 'RNF223', 'C1orf159', 'AL390719.3',\n",
       "       'LINC01342', 'AL390719.2', 'TTLL10-AS1', 'TTLL10', 'TNFRSF18',\n",
       "       'TNFRSF4', 'SDF4', 'B3GALT6', 'C1QTNF12', 'AL162741.1', 'UBE2J2',\n",
       "       'LINC01786', 'SCNN1D', 'ACAP3', 'PUSL1', 'INTS11', 'AL139287.1', 'CPTP',\n",
       "       'TAS1R3', 'DVL1', 'MXRA8', 'AURKAIP1', 'CCNL2', 'MRPL20-AS1', 'MRPL20',\n",
       "       'AL391244.2', 'ANKRD65', 'AL391244.1', 'TMEM88B', 'LINC01770', 'VWA1',\n",
       "       'ATAD3C', 'ATAD3B', 'ATAD3A', 'TMEM240', 'SSU72', 'AL645728.1',\n",
       "       'FNDC10', 'AL691432.4', 'AL691432.2', 'MIB2', 'MMP23B', 'CDK11B',\n",
       "       'FO704657.1', 'SLC35E2B', 'CDK11A', 'SLC35E2A', 'NADK', 'GNB1',\n",
       "       'AL109917.1', 'CALML6', 'TMEM52'],\n",
       "      dtype='object', name='genes')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<713626x90 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 2167712 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "            h5ad_file_path = f\"./data/chunk{chunk_counter+1:04d}_output_data.h5ad\"\n",
    "            adata.write_h5ad(h5ad_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dict[\"X\"] = sparse_matrix.transpose()\n",
    "genes_ = pd.DataFrame(index = pd.concat(genes, axis=0))\n",
    "adata_dict[\"var\"] = genes_\n",
    "\n",
    "\n",
    "adata = ad.AnnData(**adata_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 713626)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_dict['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713626, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_dict['obs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes__ = pd.DataFrame(adata_dict['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "from scipy import sparse\n",
    "\n",
    "import anndata as ad\n",
    "from anndata._core.sparse_dataset import SparseDataset\n",
    "from anndata.experimental import read_elem, write_elem\n",
    "\n",
    "\n",
    "def read_everything_but_X(pth) -> ad.AnnData:\n",
    "    attrs = [\"obs\", \"var\", \"obsm\", \"varm\", \"obsp\", \"varp\", \"uns\"]\n",
    "    with h5py.File(pth) as f:\n",
    "        adata = ad.AnnData(**{k: read_elem(f[k]) for k in attrs})\n",
    "    return adata\n",
    "\n",
    "\n",
    "def concat_on_disk(input_pths: list[Path], output_pth: Path):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    input_pths\n",
    "        Paths to h5ad files which will be concatenated\n",
    "    output_pth\n",
    "        File to write as a result\n",
    "    \"\"\"\n",
    "    annotations = ad.concat([read_everything_but_X(pth) for pth in input_pths])\n",
    "\n",
    "    annotations.write_h5ad(output_pth)\n",
    "    n_variables = annotations.shape[1]\n",
    "    \n",
    "    del annotations\n",
    "\n",
    "    with h5py.File(out_pth, \"a\") as target:\n",
    "        dummy_X = sparse.csr_matrix((0, n_variables), dtype=\"float32\")\n",
    "        dummy_X.indptr = dummy_X.indptr.astype(\"int64\") # Guarding against overflow for very large datasets\n",
    "\n",
    "        write_elem(target, \"X\", dummy_X)\n",
    "        mtx = SparseDataset(target[\"X\"])\n",
    "        for p in pths:\n",
    "            with h5py.File(p, \"r\") as src:\n",
    "                mtx.append(SparseDataset(src[\"X\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import anndata as ad\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "tmp_dir = Path(\"tmp_h5ads/\")\n",
    "tmp_dir.mkdir(exist_ok=True)\n",
    "backed_adatas = []\n",
    "\n",
    "for prefix in list(\"abcde\"):\n",
    "    pth = tmp_dir / f\"{prefix}.h5ad\"\n",
    "    adata = sc.AnnData(\n",
    "        sparse.random(100, 100, density=0.3, format=\"csr\"),\n",
    "        obs=pd.DataFrame(index=[f\"{prefix}-cell{i}\" for i in range(100)])\n",
    "    )\n",
    "    adata.write(pth)\n",
    "    backed_adatas.append(ad.read_h5ad(pth, backed=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"concatenated.h5ad\", \"w\") as f:\n",
    "    ad._io.h5ad.write_attribute(f, \"X\", sparse.csr_matrix((0, 100)))\n",
    "    base_dset = ad._core.sparse_dataset.SparseDataset(f[\"X\"])\n",
    "\n",
    "    # Concatenate adatas\n",
    "    for adata in backed_adatas:\n",
    "        base_dset.append(adata.X)\n",
    "\n",
    "    ad._io.h5ad.write_attribute(f, \"obs\", pd.concat((a.obs for a in backed_adatas)))\n",
    "    ad._io.h5ad.write_attribute(f, \"var\", backed_adatas[0].var)\n",
    "\n",
    "    # Thank you ivirshup for the solution. Just wanted to add, that if you are trying this with anndata version 0.9.1, \n",
    "    # you need to replace write_attribute with write_elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From : https://github.com/scverse/anndata/issues/794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_file, \"w\") as target:\n",
    "    target.create_dataset(\n",
    "        \"X\",\n",
    "        (obs.shape[0], var.shape[0]),\n",
    "         dtype=\"float32\",\n",
    "        chunks=(1000, 1000),\n",
    "    )\n",
    "    write_elem(target, \"obs\", obs)\n",
    "    write_elem(target, \"var\", var)\n",
    "\n",
    "# read in created output file\n",
    "adata = ad.read(output_file, backed=\"r+\")\n",
    "\n",
    "counter = 0\n",
    "for f in files:\n",
    "    cur_X = ... # read in a subset of X\n",
    "    adata[counter : counter + cur_X.shape[0], :].X = cur_X # store that subset of X\n",
    "    counter += cur_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from anndata.experimental import write_elem\n",
    "\n",
    "output_file=\"test.h5ad\"\n",
    "n_cols = 10\n",
    "n_rows = 1000\n",
    "obs = pd.DataFrame({\"group\":np.arange(n_rows)})\n",
    "var = pd.DataFrame({\"feature\":np.arange(n_cols)})\n",
    "\n",
    "# dummy function for chunked X\n",
    "def get_X_chunk(chunksize=10):\n",
    "    X = np.random.random((n_rows,n_cols))\n",
    "    chunk_idx = 0\n",
    "    for i in range(chunksize,len(X)+chunksize,chunksize):\n",
    "        yield X[chunk_idx:min(i,len(X))]\n",
    "        chunk_idx += chunksize\n",
    "        \n",
    "# initialize h5ad on file\n",
    "with h5py.File(output_file, \"w\") as target:\n",
    "    target.create_dataset(\n",
    "        \"X\",\n",
    "        (obs.shape[0], var.shape[0]),\n",
    "         dtype=\"float32\",\n",
    "        chunks=(10, 10),\n",
    "    )\n",
    "    write_elem(target, \"obs\", obs)\n",
    "    write_elem(target, \"var\", var)\n",
    "    \n",
    "# read in created output file\n",
    "adata = ad.read(output_file, backed=\"r+\")\n",
    "\n",
    "# write chunks to file\n",
    "counter = 0\n",
    "for chunk in get_X_chunk():\n",
    "    adata[counter : counter + chunk.shape[0], :].X = chunk # store that subset of X\n",
    "    counter += chunk.shape[0]\n",
    "   \n",
    "### Error mode 1:\n",
    "\n",
    "adata.raw = adata\n",
    "# AttributeError: Could not find dataset for raw X in file: test.h5ad.\n",
    "\n",
    "### Error mode 2:\n",
    "print(adata.X)\n",
    "# <HDF5 dataset \"X\": shape (1000, 10), type \"<f4\">\n",
    "\n",
    "# Compare with:\n",
    "print(AnnData(X=np.hstack([*get_X_chunk()])).X)\n",
    "# -> array([[...]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scverse10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
