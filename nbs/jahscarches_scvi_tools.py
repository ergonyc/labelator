# -*- coding: utf-8 -*-
"""JAHscarches-scvi-tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cGcnML2ugi1jtJO59utL7Kj7HFbiy57B

## Reference mapping with scvi-tools

This tutorial covers the usage of the [scArches method](https://www.biorxiv.org/content/10.1101/2020.07.16.205997v1) with SCVI, SCANVI, and TOTALVI.

This particular workflow is useful in the case where a model is trained on some data (called reference here) and new samples are received (called query). The goal is to analyze these samples in the context of the reference, by mapping the query cells to the same reference latent space. This workflow may also be used in the [scarches](https://scarches.readthedocs.io/) package, but here we demonstrate using only scvi-tools.

### Imports and scvi-tools installation (colab)
"""

!pip uninstall -y typing_extensions
!pip install --quiet scvi-colab
import sys

from scvi_colab import install

install()

IN_COLAB = "google.colab" in sys.modules
if IN_COLAB:
    !pip install --quiet scrublet

import sys
import warnings

import anndata as ad
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import scrublet as scr
import scvi

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
warnings.simplefilter(action="ignore", category=FutureWarning)


sc.set_figure_params(figsize=(4, 4))
scvi.settings.seed = 94705

# %config InlineBackend.print_figure_kwargs={'facecolor' : "w"}
# %config InlineBackend.figure_format='retina'

from scipy.sparse import csr_matrix, vstack, hstack
from pathlib import Path


# File paths
obs_file_path = "/content/drive/MyDrive/SingleCellModel/cell_barcode_labels.csv"
count_matrix_file_path = "/content/drive/MyDrive/SingleCellModel/brain_atlas_full_counts_table.csv"


# Specify a larger sample size (e.g., 1e7 bytes)
sample_size = 1e7


cells = pd.read_csv(obs_file_path,index_col=0)


# Specify data types
# Assuming that the first column is object (like string) and the rest are uint8.
dtypes = {0: 'object'}
for col in range(1, 713626):  # Adjust the range based on the number of columns
    dtypes[col] = 'uint8'

adata = ad.read_h5ad("/content/drive/MyDrive/SingleCellModel/brain_atlas_anndata_FULL.h5ad")
adata.var_names_make_unique()
features = adata.var_names.tolist()

"""# Create anndata object

First, we need to make our anndata object from the ridiculously large .csv
"""

# # Define the chunk size
# chunk_size = 100  #

# # Create an empty list to store sparse matrices from each chunk
# chunk_counter = 0
# sparse_matrices = []
# genes = []
# # 1. Read the CSV in chunks using a context manager
# with pd.read_csv(count_matrix_file_path, header=0,dtype=dtypes, chunksize=chunk_size) as reader:
#     for chunk in reader:

#         print(f"chunk number {chunk_counter}")
#         # 2. get the genes
#         gene_chunk = chunk['genes']

#         #  COULD maybe filter by genes here...
#         # keep_feaets = adata0.var_names.isin(features)


#         sparse_chunk = csr_matrix(chunk.iloc[:,1:].values.T)
#         genes.append(gene_chunk)
#         sparse_matrices.append(sparse_chunk)

#         # after each 10 chunks write file and reset
#         if (chunk_counter+1) % 10 == 0:
#             sparse_matrix = hstack(sparse_matrices)
#             genes_ = pd.DataFrame(index = pd.concat(genes, axis=0))
#             genes_['chunk'] = chunk_counter

#             # adata_dict = {}
#             # adata_dict["X"] = sparse_matrix.transpose()
#             # adata_dict["obs"] = cells
#             # adata_dict["var"] = genes_
#             # # adata_dict["dtype"] = np.float64
#             # # adata_dict["obsm"] = dict(
#             # #     a=da.random.random((M, 100)),
#             # # )
#             # # adata_dict["layers"] = dict(
#             # #     a=da.random.random((M, N)),
#             # # )
#             print(f"matrix shape {sparse_matrix.shape} \n var shape {genes_.shape} obs shape {cells.shape[0]}")


#             adata = ad.AnnData(X=sparse_matrix, obs=cells, var=genes_)
#             # adata = ad.AnnData(**adata_dict)
#             h5ad_file_path = f"/content/drive/MyDrive/SingleCellModel/data/chunk{chunk_counter+1:04d}_output_data.h5ad"
#             adata.write_h5ad(h5ad_file_path)
#             del adata
#             print(f"wrote {genes_.shape} genes to adata file {h5ad_file_path.split('/')[-1]}")
#             sparse_matrices = []
#             genes = []

#         chunk_counter += 1

# data_folder = Path("/content/drive/MyDrive/SingleCellModel/data/")
# pattern = f"chunk0*_output_data.h5ad"
# chunk_fs = sorted(data_folder.glob(pattern))


# # load the first file
# adata0 = ad.read_h5ad(chunk_fs[0])
# # subset it to the features in features.
# keep_feaets = adata0.var_names.isin(features)


# adata0 = adata0[:, keep_feaets]
# adata0

# for chunk_n, chunk in enumerate(chunk_fs[1:]):
#     print(f"loading {chunk}")
#     adata = ad.read_h5ad(chunk)
#     keep_feats = adata.var_names.isin(features)
#     adata = adata[:, keep_feats]
#     adata0 = ad.concat([adata0, adata], axis=1)
#     print(f"adata0 shape: {adata0.shape}")
#     if chunk_n % 10 == 0:
#         print(f"writing to disk")
#         adata0.write_h5ad(f"brain_atlas_anndata_{chunk_n}.h5ad")
#         print(f"done writing to disk")

"""### Reference mapping with SCVI"""

# # import pandas as pd
# from scipy.sparse import vstack

# cell_bc_path = "/content/drive/MyDrive/SingleCellModel/brain_atlas_anndata.h5ad"

# # !tar -tf  '/content/drive/MyDrive/SingleCellModel/rna_model_files.tar'

# adata = anndata.read_h5ad(cell_bc_path)

"""We consider the SS2 and CelSeq2 samples as query, and all the others as reference."""

adata

# clean_samples_path = "/content/drive/MyDrive/SingleCellModel/Model Combinations - clean_samples_138.csv"
# clean_samples = pd.read_csv(clean_samples_path)

# batch_mapper = dict(zip(clean_samples["sample"], clean_samples["batch"]))

# adata.obs["batch"] = adata.obs["sample"].map(batch_mapper)

test_samples_path = "/content/drive/MyDrive/SingleCellModel/Model Combinations - training_set_98.csv"
test_samples = pd.read_csv(test_samples_path)

test_samples.head()

query_mask = np.array(
    [s in test_samples['sample'].values for s in adata.obs["sample"]]
)

adata_ref = adata[query_mask].copy()
adata_query = adata[~query_mask].copy()

adata_ref.shape, adata_query.shape

"""We already have highly variable gene selected"""

# sc.pp.highly_variable_genes(adata_ref, n_top_genes=2000, batch_key="tech", subset=True)

# adata_query = adata_query[:, adata_ref.var_names].copy()

"""#### Train reference

We train the reference using the standard SCVI workflow, except we add a few non-default parameters that were identified to work well with scArches.
"""

scvi.model.SCVI.setup_anndata(adata_ref, batch_key="batch", layer="counts")

arches_params = dict(
    use_layer_norm="both",
    use_batch_norm="none",
    encode_covariates=True,
    dropout_rate=0.2,
    n_layers=2,
)

vae_path = Path("/content/drive/MyDrive/SingleCellModel/model")
vae_path.as_posix()

vae_path = Path("/content/drive/MyDrive/SingleCellModel/model")
vae_path.as_posix()

if vae_path.exists():
  vae_ref = scvi.model.SCVI.load(vae_path.as_posix(), adata_ref)
else:
  vae_ref = scvi.model.SCVI(adata_ref, **arches_params)
  vae_ref.train()

"""Now we obtain the latent representation, and use Scanpy to visualize with UMAP."""

adata_ref.obsm["X_scVI"] = vae_ref.get_latent_representation()
sc.pp.neighbors(adata_ref, use_rep="X_scVI")
# sc.tl.leiden(adata_ref)
# sc.tl.umap(adata_ref)

sc.tl.leiden(adata_ref)
sc.tl.umap(adata_ref)

sc.pl.umap(
    adata_ref,
    color=["batch", "cell_type"],
    frameon=False,
    ncols=1,
)

"""#### Update with query

We can load a new model with the query data either using

1. The saved reference model
1. The instance of the reference model
"""

# save the reference model
# dir_path = "/content/drive/MyDrive/SingleCellModel/model/"
vae_ref.save(vae_path, overwrite=True)

"""First we validate that our query data is ready to be loaded into the reference model. Here we run `prepare_query_anndata`, which reorders the genes and pads any missing genes with 0s. This should generally be run before reference mapping with scArches to ensure data correctness. In the case of this tutorial, nothing happens as the query data is already "correct"."""

# both are valid
# scvi.model.SCVI.prepare_query_anndata(adata_query, dir_path)
scvi.model.SCVI.prepare_query_anndata(adata_query, vae_ref)

"""Now we create the new query model instance."""

# # both are valid
# vae_q = scvi.model.SCVI.load_query_data(
#     adata_query,
#     dir_path,
# )
vae_q = scvi.model.SCVI.load_query_data(
    adata_query,
    vae_ref,
)

"""This is a typical `SCVI` object, and after training, can be used in any defined way.

For training the query data, we recommend using a `weight_decay` of 0.0. This ensures the latent representation of the reference cells will remain exactly the same if passing them through this new query model.
"""

vae_q_path = Path("/content/drive/MyDrive/SingleCellModel/qmodel")

if vae_q_path.exists():
  vae_q = scvi.model.SCVI.load(vae_path.as_posix(), adata_query)
else:
  vae_q.train()
  vae_q.save(vae_q_path, overwrite=True)

adata_query.obsm["X_scVI"] = vae_q.get_latent_representation()

sc.pp.neighbors(adata_query, use_rep="X_scVI")
sc.tl.leiden(adata_query)
sc.tl.umap(adata_query)

sc.pl.umap(
    adata_query,
    color=["batch", "cell_type"],
    frameon=False,
    ncols=1,
)



"""#### Visualize reference and query"""

# adata_full = adata_query.concatenate(adata_ref)
adata_full = ad.concat( [adata_query,adata_ref] )

"""The concatenated object has the latent representations of both reference and query, but we are also able to reobtain these values using the query model."""

adata_full.obsm["X_scVI"] = vae_q.get_latent_representation(adata_full)

vae_q.adata_manager.view_registry()

sc.pp.neighbors(adata_full, use_rep="X_scVI")
sc.tl.leiden(adata_full)
sc.tl.umap(adata_full)

sc.pl.umap(
    adata_full,
    color=["batch", "cell_type"],
    frameon=False,
    ncols=1,
)

adata_ref.write_h5ad("/content/drive/MyDrive/SingleCellModel/adata_ref.h5ad")

adata_query.write_h5ad("/content/drive/MyDrive/SingleCellModel/adata_query.h5ad")
adata_full.write_h5ad("/content/drive/MyDrive/SingleCellModel/adata_full.h5ad")

# raw = adata.raw.to_adata()

"""### Reference mapping with SCANVI

We'll use the same Pancreas dataset, this time we set it up such that we register that the dataset has labels.

The advantage of SCANVI is that we'll be able to predict the cell type labels of the query dataset. In the case of SCVI, a separate classifier (e.g., nearest-neighbor, random forest, etc.) would have to be trained on the reference latent space.
"""

adata_ref = ad.read_h5ad("/content/drive/MyDrive/SingleCellModel/adata_ref.h5ad")

# adata_query.write_h5ad("adata_query.h5ad")
# adata_full.write_h5ad("adata_full.h5ad")

vae_path = Path("/content/drive/MyDrive/SingleCellModel/model")
vae_ref = scvi.model.SCVI.load(vae_path.as_posix(), adata_ref)

"""#### Train reference

`SCANVI` tends to perform better in situations where it has been initialized using a pre-trained `SCVI` model. In this case, we will use `vae_ref` that we have already trained above. In other words, a typical `SCANVI` workflow will be:

```python
scvi_model = SCVI(adata_ref, **arches_params)
scvi_model.train()
scanvi_model = SCANVI.from_scvi_model(scvi_model, unlabeled_category="Unknown")
scanvi_model.train()
```

`SCANVI.from_scvi_model` will also run `setup_anndata`. It will use the `batch_key` and `layer` used with `SCVI`, but here we add the `labels_key`.

For this part of the tutorial, we will create a new labels key in the reference anndata object to reflect the common scenario of having no labels for the query data.

Applying this workflow in the context of this tutorial:
"""

adata_ref.obs["labels_scanvi"] = adata_ref.obs["cell_type"].values

# unlabeled category does not exist in adata.obs[labels_key]
# so all cells are treated as labeled
vae_ref_scan = scvi.model.SCANVI.from_scvi_model(
    vae_ref,
    unlabeled_category="Unknown",
    labels_key="labels_scanvi",
)

vae_ref_scan.train(max_epochs=20, n_samples_per_label=100)

adata_ref.obsm["X_scANVI"] = vae_ref_scan.get_latent_representation()
sc.pp.neighbors(adata_ref, use_rep="X_scANVI")

sc.tl.leiden(adata_ref)
sc.tl.umap(adata_ref)

sc.pl.umap(
    adata_ref,
    color=["batch", "cell_type"],
    frameon=False,
    ncols=1,
)

"""#### Update with query"""

dir_path_scan =  "/content/drive/MyDrive/SingleCellModel/my_model_scanvi/"
# vae_ref_scan.save(dir_path_scan, overwrite=True)

vae_ref_scan.save(dir_path_scan, overwrite=True)

adata_query = ad.read_h5ad("/content/drive/MyDrive/SingleCellModel/adata_query.h5ad")

# again a no-op in this tutorial, but good practice to use
scvi.model.SCANVI.prepare_query_anndata(adata_query, dir_path_scan)

"""Notice that `adata_query.obs["labels_scanvi"]` does not exist. The `load_query_data` method detects this and fills it in `adata_query` with the unlabeled category (here `"Unknown"`)."""

vae_q = scvi.model.SCANVI.load_query_data(
    adata_query,
    dir_path_scan,
)

vae_q.train(
    max_epochs=100,
    plan_kwargs=dict(weight_decay=0.0),
    check_val_every_n_epoch=10,
)

dir_path_qscan =  "/content/drive/MyDrive/SingleCellModel/my_qmodel_scanvi/"
vae_q.save(dir_path_qscan, overwrite=True)

adata_query.obsm["X_scANVI"] = vae_q.get_latent_representation()
adata_query.obs["predictions"] = vae_q.predict()

df = adata_query.obs.groupby(["cell_type", "predictions"]).size().unstack(fill_value=0)
norm_df = df / df.sum(axis=0)

plt.figure(figsize=(8, 8))
_ = plt.pcolor(norm_df)
_ = plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns, rotation=90)
_ = plt.yticks(np.arange(0.5, len(df.index), 1), df.index)
plt.xlabel("Predicted")
plt.ylabel("Observed")

norm_df

"""#### Analyze reference and query"""

# adata_full = adata_query.concatenate(adata_ref)
adata_full = ad.concat( [adata_ref, adata_query])

"""This just makes a column in the anndata corresponding to if the data come from the reference or query sets."""

adata_full.obs.batch.cat.rename_categories(["Query", "Reference"], inplace=True)

full_predictions = vae_q.predict(adata_full)
print(f"Acc: {np.mean(full_predictions == adata_full.obs.celltype)}")

adata_full.obs["predictions"] = full_predictions

sc.pp.neighbors(adata_full, use_rep="X_scANVI")
sc.tl.leiden(adata_full)
sc.tl.umap(adata_full)

# sc.pl.umap(
#     adata_full,
#     color=["tech", "celltype"],
#     frameon=False,
#     ncols=1,
# )

sc.pl.umap(
    adata_full,
    color=["batch", "cell_type"],
    frameon=False,
    ncols=1,
)

ax = sc.pl.umap(
    adata_full,
    frameon=False,
    show=False,
)
sc.pl.umap(
    adata_full[: adata_query.n_obs],
    color=["predictions"],
    frameon=False,
    title="Query predictions",
    ax=ax,
    alpha=0.7,
)

ax = sc.pl.umap(
    adata_full,
    frameon=False,
    show=False,
)
sc.pl.umap(
    adata_full[: adata_query.n_obs],
    color=["cell_type"],
    frameon=False,
    title="Query observed cell types",
    ax=ax,
    alpha=0.7,
)

adata_ref.write_h5ad("/content/drive/MyDrive/SingleCellModel/scanvi_adata_ref.h5ad")

adata_query.write_h5ad("/content/drive/MyDrive/SingleCellModel/scanvi_adata_query.h5ad")
adata_full.write_h5ad("/content/drive/MyDrive/SingleCellModel/scanvi_adata_full.h5ad")

"""### Reference mapping with TOTALVI

This workflow works very similarly for TOTALVI. Here we demonstrate how to build a CITE-seq reference and use scRNA-seq only data as the query.

#### Assemble data

For totalVI, we will treat two CITE-seq PBMC datasets from 10X Genomics as the reference. These datasets were already filtered for outliers like doublets, as described in the totalVI manuscript. There are 14 proteins in the reference.
"""

adata_ref = scvi.data.pbmcs_10x_cite_seq()

"""In general, there will be some necessary data wrangling. For example, we need to provide totalVI with some protein data -- and when it's all zeros, totalVI identifies that the protein data is missing in this "batch".

It could have also been the case that only some of the protein data was missing, in which case we would add zeros for each of the missing proteins.
"""

adata_query = scvi.data.dataset_10x("pbmc_10k_v3")
adata_query.obs["batch"] = "PBMC 10k (RNA only)"
# put matrix of zeros for protein expression (considered missing)
pro_exp = adata_ref.obsm["protein_expression"]
data = np.zeros((adata_query.n_obs, pro_exp.shape[1]))
adata_query.obsm["protein_expression"] = pd.DataFrame(
    columns=pro_exp.columns, index=adata_query.obs_names, data=data
)

"""We do some light QC filtering on the query dataset (doublets, mitochondrial, etc.)"""

scrub = scr.Scrublet(adata_query.X)
doublet_scores, predicted_doublets = scrub.scrub_doublets()
adata_query = adata_query[~predicted_doublets].copy()

adata_query.var["mt"] = adata_query.var_names.str.startswith(
    "MT-"
)  # annotate the group of mitochondrial genes as 'mt'
sc.pp.calculate_qc_metrics(
    adata_query, qc_vars=["mt"], percent_top=None, log1p=False, inplace=True
)
adata_query = adata_query[adata_query.obs.pct_counts_mt < 15, :].copy()

"""Now to concatenate the objects, which intersects the genes properly."""

adata_full = anndata.concat([adata_ref, adata_query])

"""And split them back up into reference and query (but now genes are properly aligned between objects)."""

adata_ref = adata_full[
    np.logical_or(adata_full.obs.batch == "PBMC5k", adata_full.obs.batch == "PBMC10k")
].copy()
adata_query = adata_full[adata_full.obs.batch == "PBMC 10k (RNA only)"].copy()

"""We run gene selection on the reference, because that's all that will be avaialble to us at first."""

sc.pp.highly_variable_genes(
    adata_ref,
    n_top_genes=4000,
    flavor="seurat_v3",
    batch_key="batch",
    subset=True,
)

"""Finally, we use these selected genes for the query dataset as well."""

adata_query = adata_query[:, adata_ref.var_names].copy()

"""#### Train reference"""

scvi.model.TOTALVI.setup_anndata(
    adata_ref, batch_key="batch", protein_expression_obsm_key="protein_expression"
)

arches_params = dict(
    use_layer_norm="both",
    use_batch_norm="none",
)
vae_ref = scvi.model.TOTALVI(adata_ref, **arches_params)

vae_ref.train()

adata_ref.obsm["X_totalVI"] = vae_ref.get_latent_representation()
sc.pp.neighbors(adata_ref, use_rep="X_totalVI")
sc.tl.umap(adata_ref, min_dist=0.4)

sc.pl.umap(adata_ref, color=["batch"], frameon=False, ncols=1, title="Reference")

dir_path = "saved_model/"
vae_ref.save(dir_path, overwrite=True)

"""#### Update with query"""

scvi.model.TOTALVI.prepare_query_anndata(adata_query, dir_path)
vae_q = scvi.model.TOTALVI.load_query_data(
    adata_query,
    dir_path,
)

vae_q.train(200, plan_kwargs=dict(weight_decay=0.0))

adata_query.obsm["X_totalVI"] = vae_q.get_latent_representation()
sc.pp.neighbors(adata_query, use_rep="X_totalVI")
sc.tl.umap(adata_query, min_dist=0.4)

"""#### Impute protein data for query and visualize

Now that we have updated with the query, we can impute the proteins that were observed in the reference, using the `transform_batch` parameter.
"""

_, imputed_proteins = vae_q.get_normalized_expression(
    adata_query,
    n_samples=10,
    return_mean=True,
    transform_batch=["PBMC10k", "PBMC5k"],
)

"""Very quickly we can identify the major expected subpopulations of B cells, CD4 T cells, CD8 T cells, monocytes, etc."""

adata_query.obs = pd.concat([adata_query.obs, imputed_proteins], axis=1)

sc.pl.umap(
    adata_query,
    color=imputed_proteins.columns,
    frameon=False,
    ncols=3,
)

"""#### Visualize reference and query"""

adata_full_new = adata_query.concatenate(adata_ref, batch_key="none")

adata_full_new.obsm["X_totalVI"] = vae_q.get_latent_representation(adata_full_new)
sc.pp.neighbors(adata_full_new, use_rep="X_totalVI")
sc.tl.umap(adata_full_new, min_dist=0.3)

_, imputed_proteins_all = vae_q.get_normalized_expression(
    adata_full_new,
    n_samples=10,
    return_mean=True,
    transform_batch=["PBMC10k", "PBMC5k"],
)

for i, p in enumerate(imputed_proteins_all.columns):
    adata_full_new.obs[p] = imputed_proteins_all[p].to_numpy().copy()

perm_inds = np.random.permutation(np.arange(adata_full_new.n_obs))
sc.pl.umap(
    adata_full_new[perm_inds],
    color=["batch"],
    frameon=False,
    ncols=1,
    title="Reference and query",
)

ax = sc.pl.umap(
    adata_full_new,
    color="batch",
    groups=["PBMC 10k (RNA only)"],
    frameon=False,
    ncols=1,
    title="Reference and query",
    alpha=0.4,
)

sc.pl.umap(
    adata_full_new,
    color=imputed_proteins_all.columns,
    frameon=False,
    ncols=3,
    vmax="p99",
)