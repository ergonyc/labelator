{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.io import mmwrite\n",
    "\n",
    "\n",
    "# File paths\n",
    "obs_file_path = \"cell_barcde_labels.csv\"\n",
    "count_matrix_file_path = \"brain_atlas_full_counts_table.csv\"\n",
    "\n",
    "# Paths\n",
    "obs_file_path = \"./data/cell_barcode_labels.csv\"\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "h5ad_file_path = \"./data/dask_output_data.h5ad\"\n",
    "\n",
    "\n",
    "# Specify a larger sample size (e.g., 1e7 bytes)\n",
    "sample_size = 1e7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use Dask to read the cell labels\n",
    "cells = dd.read_csv(obs_file_path, assume_missing=True)\n",
    "# cells = obs_dd.compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Delayed('int-77162108-dbce-44a6-a370-a59a035ad68e'), 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cells.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify a larger sample size in bytes (e.g., 10,000,000 bytes or 10 MB)\n",
    "sample_size = 100000000\n",
    "\n",
    "# Specify data types\n",
    "# Assuming that the first column is object (like string) and the rest are uint8.\n",
    "dtypes = {0: 'object'}\n",
    "for col in range(1, 713626):  # Adjust the range based on the number of columns\n",
    "    dtypes[col] = 'uint8'\n",
    "\n",
    "# Use Dask to read the count matrix in a lazy manner with specified data types\n",
    "# count_matrix_dd = dd.read_csv(count_matrix_file_path, dtype=dtypes, sample=sample_size)\n",
    "# Read CSV in smaller partitions\n",
    "count_matrix_dd = dd.read_csv(count_matrix_file_path, header=0,dtype=dtypes, sample=sample_size,  blocksize=1e6)  # 1MB blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Dask DataFrame to a Dask Array (excluding the index column)\n",
    "count_matrix_da = count_matrix_dd.drop(columns=count_matrix_dd.columns[0]).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix_da = count_matrix_da.map_blocks( csr_matrix )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_matrix_da = count_matrix_da.map_blocks( csr_matrix )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix_da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dict = {}\n",
    "\n",
    "adata_dict[\"X\"] = count_matrix_da.T \n",
    "# adata_dict[\"dtype\"] = np.float64\n",
    "# adata_dict[\"obsm\"] = dict(\n",
    "#     a=da.random.random((M, 100)),\n",
    "# )\n",
    "# adata_dict[\"layers\"] = dict(\n",
    "#     a=da.random.random((M, N)),\n",
    "# )\n",
    "adata_dict[\"obs\"] = cells.compute()\n",
    "\n",
    "adata_dict[\"var\"] = count_matrix_dd['genes'].compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adat = ad.AnnData(**adata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Array.to_hdf5() missing 1 required positional argument: 'datapath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m count_matrix_da\u001b[39m.\u001b[39;49mto_hdf5(h5ad_file_path, key\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcount_matrix\u001b[39;49m\u001b[39m\"\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtable\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Array.to_hdf5() missing 1 required positional argument: 'datapath'"
     ]
    }
   ],
   "source": [
    "count_matrix_da.to_hdf5(h5ad_file_path, key=\"count_matrix\", mode=\"w\", format=\"table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Compute the Dask array and convert it to a CSR sparse matrix\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sparse_matrix_csr \u001b[39m=\u001b[39m csr_matrix(count_matrix_da\u001b[39m.\u001b[39;49mcompute())\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute the Dask array and convert it to a CSR sparse matrix\n",
    "sparse_matrix_csr = csr_matrix(count_matrix_da.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write the CSR matrix to MTX format\n",
    "mmwrite(\"output_matrix_csr.mtx\", sparse_matrix_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m genes[:\u001b[39m100\u001b[39;49m]\u001b[39m.\u001b[39;49mcompute()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute the Dask array and convert it to a COO sparse matrix\n",
    "sparse_matrix = coo_matrix(data.compute())\n",
    "\n",
    "# Write the sparse matrix to MTX format\n",
    "mmwrite(\"output_matrix.mtx\", sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_1.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m var_\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mDataFrame(index\u001b[39m=\u001b[39;49mgenes[:\u001b[39m100\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/frame.py:807\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    798\u001b[0m             mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    799\u001b[0m                 data,\n\u001b[1;32m    800\u001b[0m                 index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    805\u001b[0m             )\n\u001b[1;32m    806\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 807\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    808\u001b[0m             {},\n\u001b[1;32m    809\u001b[0m             index,\n\u001b[1;32m    810\u001b[0m             columns \u001b[39mif\u001b[39;49;00m columns \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m default_index(\u001b[39m0\u001b[39;49m),\n\u001b[1;32m    811\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    812\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    813\u001b[0m         )\n\u001b[1;32m    814\u001b[0m \u001b[39m# For data is scalar\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/internals/construction.py:438\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    436\u001b[0m     index \u001b[39m=\u001b[39m _extract_index(arrays[\u001b[39m~\u001b[39mmissing])\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    440\u001b[0m \u001b[39m# no obvious \"empty\" int column\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m missing\u001b[39m.\u001b[39many() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer_dtype(dtype):\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/indexes/base.py:7125\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7123\u001b[0m         \u001b[39mreturn\u001b[39;00m Index(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   7124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 7125\u001b[0m     \u001b[39mreturn\u001b[39;00m Index(index_like, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/indexes/base.py:551\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    548\u001b[0m         data \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39m_dtype_obj)\n\u001b[1;32m    550\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     arr \u001b[39m=\u001b[39m sanitize_array(data, \u001b[39mNone\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    552\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    553\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mindex must be specified when data is not list-like\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/construction.py:580\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    576\u001b[0m         subarr \u001b[39m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    578\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    579\u001b[0m     \u001b[39m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(data, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    581\u001b[0m     \u001b[39mreturn\u001b[39;00m sanitize_array(\n\u001b[1;32m    582\u001b[0m         data,\n\u001b[1;32m    583\u001b[0m         index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m         allow_2d\u001b[39m=\u001b[39mallow_2d,\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/dataframe/core.py:601\u001b[0m, in \u001b[0;36m_Frame.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute()\n\u001b[1;32m    602\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed)\n\u001b[1;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    172\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "var_=pd.DataFrame(index=genes[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def append_chunk_to_h5ad(adata_chunk, h5ad_path):\n",
    "    \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "    \n",
    "    if h5ad_path.exists(): # os.path.exists(h5ad_path):\n",
    "        adata_existing = anndata.read(h5ad_path)\n",
    "        adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "        adata_combined.write(h5ad_path)\n",
    "    else:\n",
    "        adata_chunk.write(h5ad_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create an empty list to store sparse matrices from each chunk\n",
    "sparse_matrices = []\n",
    "genes = []\n",
    "chunk_counter = 0\n",
    "st = time.time()\n",
    "# 1. Read the CSV in chunks using a context manager\n",
    "with pd.read_csv(count_matrix_file_path, chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk_counter += 1\n",
    "        print(f\"chunk number {chunk_counter}\")\n",
    "        # 2. get the genes\n",
    "        gene_chunk = chunk['genes']\n",
    "        genes.append(gene_chunk)\n",
    "        # 3. Convert the chunk to a sparse matrix and store\n",
    "        sparse_chunk = csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)\n",
    "        sparse_matrices.append(sparse_chunk)\n",
    "\n",
    "        lt = time.time() - st\n",
    "        print(f'read #{chunk_counter}x  = {chunk.shape} in {lt:2f}s')\n",
    "\n",
    "        st = time.time()\n",
    "\n",
    "\n",
    "# 4. Combine the sparse matrices vertically\n",
    "sparse_matrix = vstack(sparse_matrices)\n",
    "genes_ = pd.concat(genes, axis=0)\n",
    "\n",
    "adata = anndata.AnnData(X=sparse_matrix.transpose(),\n",
    "                                obs=obs_,\n",
    "                                var=pd.DataFrame(index=genes_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=count_matrix_da.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an AnnData object using Dask arrays\n",
    "adata = anndata.AnnData(X=count_matrix_da.compute(), obs=cells, var=var_)\n",
    "\n",
    "print(adata)\n",
    "adata.write(h5ad_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix_da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import anndata\n",
    "\n",
    "# File paths\n",
    "obs_file_path = \"cell_barcde_labels.csv\"\n",
    "count_matrix_file_path = \"brain_atlas_full_counts_table.csv\"\n",
    "\n",
    "# Specify a larger sample size in bytes (e.g., 10,000,000 bytes or 10 MB)\n",
    "sample_size = 10000000\n",
    "\n",
    "# Specify data types\n",
    "# Assuming that the first column is object (like string) and the rest are uint8.\n",
    "dtypes = {0: 'object'}\n",
    "for col in range(1, 71001):  # Adjust the range based on the number of columns\n",
    "    dtypes[col] = 'uint8'\n",
    "\n",
    "# Use Dask to read the count matrix in a lazy manner with specified data types\n",
    "count_matrix_dd = dd.read_csv(count_matrix_file_path, dtype=dtypes, sample=sample_size)\n",
    "genes = count_matrix_dd.columns[1:]\n",
    "\n",
    "# Use Dask to read the cell labels (assuming they are strings)\n",
    "obs_dd = dd.read_csv(obs_file_path, dtype=str, sample=sample_size)\n",
    "cells = obs_dd.compute()\n",
    "\n",
    "# Create an AnnData object\n",
    "# Compute the Dask DataFrame to get a Pandas DataFrame, then convert to numpy array\n",
    "adata = anndata.AnnData(X=count_matrix_dd.compute().values, \n",
    "                        obs=cells, \n",
    "                        var=pd.DataFrame(index=genes))\n",
    "\n",
    "print(adata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scverse10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
