{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata\n",
    "\n",
    "# Paths for the CSV files and the output .h5ad file\n",
    "obs_file_path = \"/content/drive/MyDrive/SingleCellModel/cell_barcde_labels.csv\"\n",
    "count_matrix_file_path = \"/content/drive/MyDrive/SingleCellModel/brain_atlas_full_counts_table.csv\"\n",
    "\n",
    "obs_file_path = \"./data/cell_barcde_labels.csv\"\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "\n",
    "h5ad_file_path = \"output_data.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define chunk size based on available memory and dataset dimensions\n",
    "# chunk_size = 5000  # You might need to adjust this based on your specific dataset and memory constraints\n",
    "\n",
    "# # Create an initial empty AnnData object and save to .h5ad\n",
    "# # This step initializes the .h5ad file\n",
    "# initial_adata = anndata.AnnData()\n",
    "# initial_adata.write(h5ad_file_path)\n",
    "\n",
    "# # Process data in chunks\n",
    "# obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n",
    "# count_matrix_iter = pd.read_csv(count_matrix_file_path, chunksize=chunk_size, index_col=0)\n",
    "\n",
    "# for obs_chunk, count_matrix_chunk in zip(obs_iter, count_matrix_iter):\n",
    "#     # Create an AnnData object for the current chunk\n",
    "#     chunk_adata = anndata.AnnData(X=count_matrix_chunk.values,\n",
    "#                                   obs=obs_chunk,\n",
    "#                                   var=pd.DataFrame(index=count_matrix_chunk.index))\n",
    "    \n",
    "#     # Append the chunk to the .h5ad file\n",
    "#     chunk_adata.write(h5ad_file_path, append=True)\n",
    "\n",
    "# print(f\"Data has been saved to {h5ad_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try and sparsify the count matrix all at once and create a single anndata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# csv_file_path = 'path_to_input.csv'\n",
    "# hdf5_file_path = 'path_to_output.h5'\n",
    "# chunksize = 50  # Adjust based on your memory; this reads 5000 rows at a time\n",
    "\n",
    "# # Use the first chunk to create the HDF5 file (with overwrite mode 'w')\n",
    "# first_chunk = True\n",
    "\n",
    "# # Read the CSV in chunks\n",
    "# for chunk in pd.read_csv(csv_file_path, chunksize=chunksize):\n",
    "#     if first_chunk:\n",
    "#         chunk.to_hdf(hdf5_file_path, key='data', mode='w')\n",
    "#         first_chunk = False\n",
    "#     else:\n",
    "#         chunk.to_hdf(hdf5_file_path, key='data', mode='a', format='table', append=True)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "\n",
    "# Parameters\n",
    "filename = 'sparse_data.csv'\n",
    "chunk_size = 10  # Adjust based on your memory capacity\n",
    "\n",
    "# Initialize a list to store sparse matrices\n",
    "sparse_chunks = []\n",
    "\n",
    "# Calculate total number of rows in the CSV to determine loop iterations\n",
    "with open(count_matrix_file_path, 'r') as f:\n",
    "    num_lines = sum(1 for line in f) - 1  # Subtract 1 to exclude the header\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the CSV in chunks and convert to sparse matrices\n",
    "for i in range(0, num_lines, chunk_size):\n",
    "    chunk = np.genfromtxt(count_matrix_file_path, delimiter=',', skip_header=i+1, max_rows=chunk_size)\n",
    "    sparse_chunk = csr_matrix(chunk)\n",
    "    sparse_chunks.append(sparse_chunk)\n",
    "    break\n",
    "\n",
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the sparse matrices\n",
    "\n",
    "sparse_matrix = vstack(sparse_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read chunks of the count matrix and append to an adata objet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def append_chunk_to_h5ad(adata_chunk, h5ad_path):\n",
    "    \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "    \n",
    "    if h5ad_path.exists(): # os.path.exists(h5ad_path):\n",
    "        adata_existing = anndata.read(h5ad_path)\n",
    "        adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "        adata_combined.write(h5ad_path)\n",
    "    else:\n",
    "        adata_chunk.write(h5ad_path)\n",
    "\n",
    "\n",
    "\n",
    "# Paths\n",
    "obs_file_path = \"./data/cell_barcode_labels.csv\"\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "h5ad_file_path = \"./data/output_data.h5ad\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the entire obs table\n",
    "\n",
    "obs_ = pd.read_csv(obs_file_path,index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number 1\n",
      "read #1x  = (50, 713627) in 144.801319s\n",
      "chunk number 2\n",
      "read #2x  = (50, 713627) in 145.000706s\n",
      "chunk number 3\n",
      "read #3x  = (50, 713627) in 144.864834s\n",
      "chunk number 4\n",
      "read #4x  = (50, 713627) in 143.185682s\n",
      "chunk number 5\n",
      "read #5x  = (50, 713627) in 173.006080s\n",
      "chunk number 6\n",
      "read #6x  = (50, 713627) in 2143.327178s\n",
      "chunk number 7\n",
      "read #7x  = (50, 713627) in 143.198500s\n",
      "chunk number 8\n",
      "read #8x  = (50, 713627) in 143.815643s\n",
      "chunk number 9\n",
      "read #9x  = (50, 713627) in 144.206183s\n",
      "chunk number 10\n",
      "read #10x  = (50, 713627) in 144.942606s\n",
      "chunk number 11\n",
      "read #11x  = (50, 713627) in 143.810245s\n",
      "chunk number 12\n",
      "read #12x  = (50, 713627) in 143.988863s\n",
      "chunk number 13\n",
      "read #13x  = (50, 713627) in 143.070242s\n",
      "chunk number 14\n",
      "read #14x  = (50, 713627) in 143.015940s\n",
      "chunk number 15\n",
      "read #15x  = (50, 713627) in 141.978829s\n",
      "chunk number 16\n",
      "read #16x  = (50, 713627) in 141.454021s\n",
      "chunk number 17\n",
      "read #17x  = (50, 713627) in 140.904442s\n",
      "chunk number 18\n",
      "read #18x  = (50, 713627) in 140.689474s\n",
      "chunk number 19\n",
      "read #19x  = (50, 713627) in 827.188770s\n",
      "chunk number 20\n",
      "read #20x  = (50, 713627) in 144.025051s\n",
      "chunk number 21\n",
      "read #21x  = (50, 713627) in 141.084366s\n",
      "chunk number 22\n",
      "read #22x  = (50, 713627) in 141.672672s\n",
      "chunk number 23\n",
      "read #23x  = (50, 713627) in 141.343088s\n",
      "chunk number 24\n",
      "read #24x  = (50, 713627) in 141.052018s\n",
      "chunk number 25\n",
      "read #25x  = (50, 713627) in 141.558494s\n",
      "chunk number 26\n",
      "read #26x  = (50, 713627) in 144.552013s\n",
      "chunk number 27\n",
      "read #27x  = (50, 713627) in 848.433476s\n",
      "chunk number 28\n",
      "read #28x  = (50, 713627) in 1990.436938s\n",
      "chunk number 29\n",
      "read #29x  = (50, 713627) in 142.666874s\n",
      "chunk number 30\n",
      "read #30x  = (50, 713627) in 145.498565s\n",
      "chunk number 31\n",
      "read #31x  = (50, 713627) in 142.885365s\n",
      "chunk number 32\n",
      "read #32x  = (50, 713627) in 144.373231s\n",
      "chunk number 33\n",
      "read #33x  = (50, 713627) in 142.680507s\n",
      "chunk number 34\n",
      "read #34x  = (50, 713627) in 145.708034s\n",
      "chunk number 35\n",
      "read #35x  = (50, 713627) in 145.346687s\n",
      "chunk number 36\n",
      "read #36x  = (50, 713627) in 143.479381s\n",
      "chunk number 37\n",
      "read #37x  = (50, 713627) in 145.675622s\n",
      "chunk number 38\n",
      "read #38x  = (50, 713627) in 143.044411s\n",
      "chunk number 39\n",
      "read #39x  = (50, 713627) in 144.685220s\n",
      "chunk number 40\n",
      "read #40x  = (50, 713627) in 143.286703s\n",
      "chunk number 41\n",
      "read #41x  = (50, 713627) in 144.017734s\n",
      "chunk number 42\n",
      "read #42x  = (50, 713627) in 144.512219s\n",
      "chunk number 43\n",
      "read #43x  = (50, 713627) in 143.069683s\n",
      "chunk number 44\n",
      "read #44x  = (50, 713627) in 144.604620s\n",
      "chunk number 45\n",
      "read #45x  = (50, 713627) in 143.561469s\n",
      "chunk number 46\n",
      "read #46x  = (50, 713627) in 143.148333s\n",
      "chunk number 47\n",
      "read #47x  = (50, 713627) in 143.390558s\n",
      "chunk number 48\n",
      "read #48x  = (50, 713627) in 144.079454s\n",
      "chunk number 49\n",
      "read #49x  = (50, 713627) in 143.380672s\n",
      "chunk number 50\n",
      "read #50x  = (50, 713627) in 147.825000s\n",
      "chunk number 51\n",
      "read #51x  = (50, 713627) in 154.332938s\n",
      "chunk number 52\n",
      "read #52x  = (50, 713627) in 153.216076s\n",
      "chunk number 53\n",
      "read #53x  = (50, 713627) in 153.902551s\n",
      "chunk number 54\n",
      "read #54x  = (50, 713627) in 153.808591s\n",
      "chunk number 55\n",
      "read #55x  = (50, 713627) in 152.886314s\n",
      "chunk number 56\n",
      "read #56x  = (50, 713627) in 152.322022s\n",
      "chunk number 57\n",
      "read #57x  = (50, 713627) in 152.413230s\n",
      "chunk number 58\n",
      "read #58x  = (50, 713627) in 154.095224s\n",
      "chunk number 59\n",
      "read #59x  = (50, 713627) in 153.839222s\n",
      "chunk number 60\n",
      "read #60x  = (50, 713627) in 154.090159s\n",
      "chunk number 61\n",
      "read #61x  = (50, 713627) in 154.747900s\n",
      "chunk number 62\n",
      "read #62x  = (50, 713627) in 154.001097s\n",
      "chunk number 63\n",
      "read #63x  = (50, 713627) in 153.638297s\n",
      "chunk number 64\n",
      "read #64x  = (50, 713627) in 154.068223s\n",
      "chunk number 65\n",
      "read #65x  = (50, 713627) in 152.417613s\n",
      "chunk number 66\n",
      "read #66x  = (50, 713627) in 146.305634s\n",
      "chunk number 67\n",
      "read #67x  = (50, 713627) in 144.364945s\n",
      "chunk number 68\n",
      "read #68x  = (50, 713627) in 145.073756s\n",
      "chunk number 69\n",
      "read #69x  = (50, 713627) in 144.062966s\n",
      "chunk number 70\n",
      "read #70x  = (50, 713627) in 145.013388s\n",
      "chunk number 71\n",
      "read #71x  = (50, 713627) in 566.171053s\n",
      "chunk number 72\n",
      "read #72x  = (50, 713627) in 2018.136199s\n",
      "chunk number 73\n",
      "read #73x  = (50, 713627) in 1378.666595s\n",
      "chunk number 74\n",
      "read #74x  = (50, 713627) in 182.558757s\n",
      "chunk number 75\n",
      "read #75x  = (50, 713627) in 148.790295s\n",
      "chunk number 76\n",
      "read #76x  = (50, 713627) in 1902.963022s\n",
      "chunk number 77\n",
      "read #77x  = (50, 713627) in 1498.527559s\n",
      "chunk number 78\n",
      "read #78x  = (50, 713627) in 441.416441s\n",
      "chunk number 79\n",
      "read #79x  = (50, 713627) in 145.134478s\n",
      "chunk number 80\n",
      "read #80x  = (50, 713627) in 143.565785s\n",
      "chunk number 81\n",
      "read #81x  = (50, 713627) in 144.223841s\n",
      "chunk number 82\n",
      "read #82x  = (50, 713627) in 143.650155s\n",
      "chunk number 83\n",
      "read #83x  = (50, 713627) in 142.793822s\n",
      "chunk number 84\n",
      "read #84x  = (50, 713627) in 142.287719s\n",
      "chunk number 85\n",
      "read #85x  = (50, 713627) in 143.393381s\n",
      "chunk number 86\n",
      "read #86x  = (50, 713627) in 142.592732s\n",
      "chunk number 87\n",
      "read #87x  = (50, 713627) in 143.718149s\n",
      "chunk number 88\n",
      "read #88x  = (50, 713627) in 527.073462s\n",
      "chunk number 89\n",
      "read #89x  = (50, 713627) in 143.534379s\n",
      "chunk number 90\n",
      "read #90x  = (50, 713627) in 142.985425s\n",
      "chunk number 91\n",
      "read #91x  = (50, 713627) in 145.289090s\n",
      "chunk number 92\n",
      "read #92x  = (50, 713627) in 145.814587s\n",
      "chunk number 93\n",
      "read #93x  = (50, 713627) in 146.564608s\n",
      "chunk number 94\n",
      "read #94x  = (50, 713627) in 143.813161s\n",
      "chunk number 95\n",
      "read #95x  = (50, 713627) in 143.521096s\n",
      "chunk number 96\n",
      "read #96x  = (50, 713627) in 142.936771s\n",
      "chunk number 97\n",
      "read #97x  = (50, 713627) in 144.074093s\n",
      "chunk number 98\n",
      "read #98x  = (50, 713627) in 144.822428s\n",
      "chunk number 99\n",
      "read #99x  = (50, 713627) in 144.644464s\n",
      "chunk number 100\n",
      "read #100x  = (50, 713627) in 144.310491s\n",
      "chunk number 101\n",
      "read #101x  = (50, 713627) in 145.146273s\n",
      "chunk number 102\n",
      "read #102x  = (50, 713627) in 148.774592s\n",
      "chunk number 103\n",
      "read #103x  = (50, 713627) in 146.394085s\n",
      "chunk number 104\n",
      "read #104x  = (50, 713627) in 142.312954s\n",
      "chunk number 105\n",
      "read #105x  = (50, 713627) in 141.238625s\n",
      "chunk number 106\n",
      "read #106x  = (50, 713627) in 143.395445s\n",
      "chunk number 107\n",
      "read #107x  = (50, 713627) in 142.357216s\n",
      "chunk number 108\n",
      "read #108x  = (50, 713627) in 146.520465s\n",
      "chunk number 109\n",
      "read #109x  = (50, 713627) in 187.325806s\n",
      "chunk number 110\n",
      "read #110x  = (50, 713627) in 154.430661s\n",
      "chunk number 111\n",
      "read #111x  = (50, 713627) in 1731.121007s\n",
      "chunk number 112\n",
      "read #112x  = (50, 713627) in 1392.765939s\n",
      "chunk number 113\n",
      "read #113x  = (50, 713627) in 375.342860s\n",
      "chunk number 114\n",
      "read #114x  = (50, 713627) in 378.744604s\n",
      "chunk number 115\n",
      "read #115x  = (50, 713627) in 313.695003s\n",
      "chunk number 116\n",
      "read #116x  = (50, 713627) in 1155.317293s\n",
      "chunk number 117\n",
      "read #117x  = (50, 713627) in 1255.275232s\n",
      "chunk number 118\n",
      "read #118x  = (50, 713627) in 1286.289150s\n",
      "chunk number 119\n",
      "read #119x  = (50, 713627) in 1481.277027s\n",
      "chunk number 120\n",
      "read #120x  = (50, 713627) in 1379.043018s\n",
      "chunk number 121\n",
      "read #121x  = (50, 713627) in 178.700465s\n",
      "chunk number 122\n",
      "read #122x  = (50, 713627) in 1346.001525s\n",
      "chunk number 123\n",
      "read #123x  = (50, 713627) in 1988.976920s\n",
      "chunk number 124\n",
      "read #124x  = (50, 713627) in 3051.365255s\n",
      "chunk number 125\n",
      "read #125x  = (50, 713627) in 1411.279270s\n",
      "chunk number 126\n",
      "read #126x  = (50, 713627) in 1630.912417s\n",
      "chunk number 127\n",
      "read #127x  = (50, 713627) in 2201.433103s\n",
      "chunk number 128\n",
      "read #128x  = (50, 713627) in 2004.051341s\n",
      "chunk number 129\n",
      "read #129x  = (50, 713627) in 3023.090279s\n",
      "chunk number 130\n",
      "read #130x  = (50, 713627) in 265.475325s\n",
      "chunk number 131\n",
      "read #131x  = (50, 713627) in 2718.342954s\n",
      "chunk number 132\n",
      "read #132x  = (50, 713627) in 2115.111424s\n",
      "chunk number 133\n",
      "read #133x  = (50, 713627) in 2013.000863s\n",
      "chunk number 134\n",
      "read #134x  = (50, 713627) in 2093.707888s\n",
      "chunk number 135\n",
      "read #135x  = (50, 713627) in 2987.030308s\n",
      "chunk number 136\n",
      "read #136x  = (50, 713627) in 1787.856473s\n",
      "chunk number 137\n",
      "read #137x  = (50, 713627) in 2913.586539s\n",
      "chunk number 138\n",
      "read #138x  = (50, 713627) in 1946.143731s\n",
      "chunk number 139\n",
      "read #139x  = (50, 713627) in 2954.497935s\n",
      "chunk number 140\n",
      "read #140x  = (50, 713627) in 2960.154052s\n",
      "chunk number 141\n",
      "read #141x  = (50, 713627) in 587.965725s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#Y126sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# 1. Read the CSV in chunks using a context manager\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#Y126sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(count_matrix_file_path, chunksize\u001b[39m=\u001b[39mchunk_size) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#Y126sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#Y126sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         chunk_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#Y126sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchunk number \u001b[39m\u001b[39m{\u001b[39;00mchunk_counter\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1624\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   1623\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[1;32m   1625\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1626\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1733\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[0;32m-> 1733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:824\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:889\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1034\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1088\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1163\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 50  # Adjust this based on your memory capacity\n",
    "\n",
    "# Create an empty list to store sparse matrices from each chunk\n",
    "sparse_matrices = []\n",
    "genes = []\n",
    "chunk_counter = 0\n",
    "st = time.time()\n",
    "# 1. Read the CSV in chunks using a context manager\n",
    "with pd.read_csv(count_matrix_file_path, chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk_counter += 1\n",
    "        print(f\"chunk number {chunk_counter}\")\n",
    "        # 2. get the genes\n",
    "        gene_chunk = chunk['genes']\n",
    "        genes.append(gene_chunk)\n",
    "        # 3. Convert the chunk to a sparse matrix and store\n",
    "        sparse_chunk = csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)\n",
    "        sparse_matrices.append(sparse_chunk)\n",
    "\n",
    "        lt = time.time() - st\n",
    "        print(f'read #{chunk_counter}x  = {chunk.shape} in {lt:2f}s')\n",
    "\n",
    "        st = time.time()\n",
    "\n",
    "\n",
    "# 4. Combine the sparse matrices vertically\n",
    "sparse_matrix = vstack(sparse_matrices)\n",
    "genes_ = pd.concat(genes, axis=0)\n",
    "\n",
    "adata = anndata.AnnData(X=sparse_matrix.transpose(),\n",
    "                                obs=obs_,\n",
    "                                var=pd.DataFrame(index=genes_))\n",
    "\n",
    "\n",
    "adata.write(f\"./data/chunk{chunk_size}_output_data.h5ad\")\n",
    "total_reads = sparse_matrix.shape[0] * sparse_matrix.shape[1]\n",
    "print(f'read {chunk_size}x10 = {total_reads} in {etime:2f}s')\n",
    "print(f'speed {chunk_size}= {total_reads/etime:2f} reads/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_chunk = count_matrix_iter.get_chunk().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number 1\n",
      "chunk number 2\n",
      "chunk number 3\n",
      "chunk number 4\n",
      "chunk number 5\n",
      "chunk number 6\n",
      "chunk number 7\n",
      "chunk number 8\n",
      "chunk number 9\n",
      "chunk number 10\n",
      "read 50x10 = 356813000 in 1488.043364s\n",
      "speed 50= 239786.694811 reads/s\n",
      "chunk number 1\n",
      "chunk number 2\n",
      "chunk number 3\n",
      "chunk number 4\n",
      "chunk number 5\n",
      "chunk number 6\n",
      "chunk number 7\n",
      "chunk number 8\n",
      "chunk number 9\n",
      "chunk number 10\n",
      "read 100x10 = 713626000 in 2943.040450s\n",
      "speed 100= 242479.168112 reads/s\n",
      "chunk number 1\n",
      "chunk number 2\n",
      "chunk number 3\n",
      "chunk number 4\n",
      "chunk number 5\n",
      "chunk number 6\n",
      "chunk number 7\n",
      "chunk number 8\n",
      "chunk number 9\n",
      "chunk number 10\n",
      "read 500x10 = 3568130000 in 50581.309304s\n",
      "speed 500= 70542.460231 reads/s\n"
     ]
    }
   ],
   "source": [
    "chunk_tests = [50, 100, 500, 1000, 5000]\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 100  # Adjust this based on your memory capacity\n",
    "for chunk_size in chunk_tests:\n",
    "    # Create an empty list to store sparse matrices from each chunk\n",
    "    sparse_matrices = []\n",
    "    genes = []\n",
    "    chunk_counter = 0\n",
    "    st = time.time()\n",
    "    # 1. Read the CSV in chunks using a context manager\n",
    "    with pd.read_csv(count_matrix_file_path, chunksize=chunk_size) as reader:\n",
    "        for chunk in reader:\n",
    "            chunk_counter += 1\n",
    "            print(f\"chunk number {chunk_counter}\")\n",
    "            # 2. get the genes\n",
    "            gene_chunk = chunk['genes']\n",
    "            genes.append(gene_chunk)\n",
    "            # 3. Convert the chunk to a sparse matrix and store\n",
    "            sparse_chunk = csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)\n",
    "            sparse_matrices.append(sparse_chunk)\n",
    "            if chunk_counter > 9:\n",
    "                break\n",
    "\n",
    "    # 3. Combine the sparse matrices vertically\n",
    "    sparse_matrix = vstack(sparse_matrices)\n",
    "    genes_ = pd.concat(genes, axis=0)\n",
    "\n",
    "    adata = anndata.AnnData(X=sparse_matrix.transpose(),\n",
    "                                    obs=obs_,\n",
    "                                    var=pd.DataFrame(index=genes_))\n",
    "\n",
    "\n",
    "    adata.write(f\"./data/chunk{chunk_size}_output_data.h5ad\")\n",
    "    total_reads = sparse_matrix.shape[0] * sparse_matrix.shape[1]\n",
    "    etime = time.time() - st\n",
    "    print(f'read {chunk_size}x10 = {total_reads} in {etime:2f}s')\n",
    "    print(f'speed {chunk_size}= {total_reads/etime:2f} reads/s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4171122994652405"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4800/748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Combine the sparse matrices vertically\n",
    "sparse_matrix = vstack(sparse_matrices)\n",
    "genes_ = pd.concat(genes, axis=0)\n",
    "\n",
    "adata = anndata.AnnData(X=sparse_matrix.transpose(),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=genes_))\n",
    "\n",
    "adata.write(h5ad_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 713626)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713626, 4800)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_chunk = scipy.sparse.csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40x713626 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 470307 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparse_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genes</th>\n",
       "      <th>MIR1302-2HG</th>\n",
       "      <th>FAM138A</th>\n",
       "      <th>OR4F5</th>\n",
       "      <th>AL627309.1</th>\n",
       "      <th>AL627309.3</th>\n",
       "      <th>AL627309.2</th>\n",
       "      <th>AL627309.5</th>\n",
       "      <th>AL627309.4</th>\n",
       "      <th>AP006222.2</th>\n",
       "      <th>AL732372.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GGCCTAATCGATTTAG-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAGTAACGTAGTCAAT-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAAAGCCAGCAGCTCA-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTCACCTCCTCCCTC-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTTCATCCAATCGCAC-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genes                 MIR1302-2HG  FAM138A  OR4F5  AL627309.1  AL627309.3   \n",
       "GGCCTAATCGATTTAG-1_1            0        0      0           0           0  \\\n",
       "TAGTAACGTAGTCAAT-1_1            0        0      0           0           0   \n",
       "GAAAGCCAGCAGCTCA-1_1            0        0      0           0           0   \n",
       "ACTCACCTCCTCCCTC-1_1            0        0      0           0           0   \n",
       "CTTCATCCAATCGCAC-1_1            0        0      0           0           0   \n",
       "\n",
       "genes                 AL627309.2  AL627309.5  AL627309.4  AP006222.2   \n",
       "GGCCTAATCGATTTAG-1_1           0           0           0           0  \\\n",
       "TAGTAACGTAGTCAAT-1_1           0           0           0           0   \n",
       "GAAAGCCAGCAGCTCA-1_1           0           0           0           0   \n",
       "ACTCACCTCCTCCCTC-1_1           0           0           0           0   \n",
       "CTTCATCCAATCGCAC-1_1           0           0           0           0   \n",
       "\n",
       "genes                 AL732372.1  \n",
       "GGCCTAATCGATTTAG-1_1           0  \n",
       "TAGTAACGTAGTCAAT-1_1           0  \n",
       "GAAAGCCAGCAGCTCA-1_1           0  \n",
       "ACTCACCTCCTCCCTC-1_1           0  \n",
       "CTTCATCCAATCGCAC-1_1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tmp = csr_matrix(count_chunk.values)\n",
    "var_ = pd.DataFrame(index=count_chunk.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((713626, 10), (713626, 3), (10, 0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_chunk.shape, obs_.shape, var_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_chunk.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713626, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adata_chunk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5ad_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# first chunk test\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m adata_chunk \u001b[39m=\u001b[39m anndata\u001b[39m.\u001b[39mAnnData(X\u001b[39m=\u001b[39mcsr_matrix(count_matrix_chunk\u001b[39m.\u001b[39mvalues),\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                   obs\u001b[39m=\u001b[39mobs_,\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                   var\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mcount_matrix_chunk\u001b[39m.\u001b[39mcolumns))\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m adata_chunk\u001b[39m.\u001b[39mwrite(h5ad_path)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h5ad_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "h5ad_file_path = \"./data/output_data.h5ad\"\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 10  # Adjust based on memory constraints\n",
    "\n",
    "# Read and process data in chunks\n",
    "# obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n",
    "obs_ = pd.read_csv(obs_file_path,index_col=0)\n",
    "\n",
    "count_matrix_iter = pd.read_csv(count_matrix_file_path, chunksize=chunk_size, index_col=0)\n",
    "\n",
    "\n",
    "count_matrix_chunk = count_matrix_iter.get_chunk().T\n",
    "\n",
    "# first chunk test\n",
    "adata_chunk = anndata.AnnData(X=csr_matrix(count_matrix_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk.write(h5ad_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIR1302-2HG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM138A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP006222.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL732372.1</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [MIR1302-2HG, FAM138A, OR4F5, AL627309.1, AL627309.3, AL627309.2, AL627309.5, AL627309.4, AP006222.2, AL732372.1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adata_chunk.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# second chunk test\n",
    "count_matrix_chunk = count_matrix_iter.get_chunk().T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk2 = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
      "\n",
      "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  warnings.warn(\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:782: UserWarning: \n",
      "AnnData expects .var.index to contain strings, but got values like:\n",
      "    []\n",
      "\n",
      "    Inferred to be: empty\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m adata_chunk\u001b[39m.\u001b[39;49mconcatenate(adata_chunk2, index_unique\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1808\u001b[0m, in \u001b[0;36mAnnData.concatenate\u001b[0;34m(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas)\u001b[0m\n",
      "\u001b[1;32m   1799\u001b[0m pat \u001b[39m=\u001b[39m \u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(batch_categories)\u001b[39m}\u001b[39;00m\u001b[39m)$\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m   1800\u001b[0m out\u001b[39m.\u001b[39mvar \u001b[39m=\u001b[39m merge_dataframes(\n",
      "\u001b[1;32m   1801\u001b[0m     [a\u001b[39m.\u001b[39mvar \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m all_adatas],\n",
      "\u001b[1;32m   1802\u001b[0m     out\u001b[39m.\u001b[39mvar_names,\n",
      "\u001b[1;32m   1803\u001b[0m     partial(merge_outer, batch_keys\u001b[39m=\u001b[39mbatch_categories, merge\u001b[39m=\u001b[39mmerge_same),\n",
      "\u001b[1;32m   1804\u001b[0m )\n",
      "\u001b[1;32m   1805\u001b[0m out\u001b[39m.\u001b[39mvar \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mvar\u001b[39m.\u001b[39miloc[\n",
      "\u001b[1;32m   1806\u001b[0m     :,\n",
      "\u001b[1;32m   1807\u001b[0m     (\n",
      "\u001b[0;32m-> 1808\u001b[0m         out\u001b[39m.\u001b[39;49mvar\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mextract(pat, expand\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m   1809\u001b[0m         \u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   1810\u001b[0m         \u001b[39m.\u001b[39margsort(kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   1811\u001b[0m     ),\n",
      "\u001b[1;32m   1812\u001b[0m ]\n",
      "\u001b[1;32m   1814\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n",
      "\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n",
      "\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n",
      "\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n",
      "\u001b[1;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n",
      "\u001b[1;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n",
      "\u001b[1;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n",
      "\u001b[1;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n",
      "\u001b[1;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n",
      "\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n",
      "\u001b[0;32m--> 181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n",
      "\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n",
      "\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n",
      "\u001b[0;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "adata_chunk.concatenate(adata_chunk2, index_unique=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "if os.path.exists(h5ad_path):\n",
    "    adata_existing = anndata.read(h5ad_path)\n",
    "    adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "    adata_combined.write(h5ad_path)\n",
    "else:\n",
    "        \n",
    "\n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "\n",
    "        \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "        if os.path.exists(h5ad_path):\n",
    "            adata_existing = anndata.read(h5ad_path)\n",
    "            adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "            adata_combined.write(h5ad_path)\n",
    "        else:\n",
    "            adata_chunk.write(h5ad_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the first chunk to create the HDF5 file (with overwrite mode 'w')\n",
    "first_chunk = True\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        count_matrix_chunk = count_matrix_iter.get_chunk()\n",
    "\n",
    "\n",
    "\n",
    "        adata_chunk = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_chunk,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "\n",
    "        \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "        if os.path.exists(h5ad_path):\n",
    "            adata_existing = anndata.read(h5ad_path)\n",
    "            adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "            adata_combined.write(h5ad_path)\n",
    "        else:\n",
    "            adata_chunk.write(h5ad_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if first_chunk:\n",
    "            count_matrix_chunk.to_hdf(hdf5_file_path, key='data', mode='w')\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            count_matrix_chunk.to_hdf(hdf5_file_path, key='data', mode='a', format='table', append=True)\n",
    "            \n",
    "\n",
    "\n",
    "        adata_chunk = anndata.AnnData(X=count_matrix_chunk.values,\n",
    "                                    obs=obs_chunk,\n",
    "                                    var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "        \n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "    except StopIteration:\n",
    "        break\n",
    "    # for obs_chunk, count_matrix_chunk in zip(obs_iter, count_matrix_iter):\n",
    "    # Create an AnnData object for the current chunk\n",
    "\n",
    "    \n",
    "        # Read the CSV in chunks\n",
    "    for chunk in pd.read_csv(csv_file_path, chunksize=chunksize):\n",
    "    if first_chunk:\n",
    "        chunk.to_hdf(hdf5_file_path, key='data', mode='w')\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        chunk.to_hdf(hdf5_file_path, key='data', mode='a', format='table', append=True)\n",
    "        \n",
    "    \n",
    "    tmp = count_matrix_chunk.values    \n",
    "\n",
    "    adata_chunk = anndata.AnnData(X=count_matrix_chunk.values,\n",
    "                                  obs=obs_chunk,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n",
    "    # Append the chunk to the .h5ad file\n",
    "    append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "    break\n",
    "print(f\"Data has been saved to {h5ad_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs_chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m obs_chunk\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obs_chunk' is not defined"
     ]
    }
   ],
   "source": [
    "obs_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/cell_barcde_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m chunk_size \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m  \u001b[39m# Adjust based on memory constraints\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read and process data in chunks\u001b[39;00m\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m obs_iter \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(obs_file_path, chunksize\u001b[39m=\u001b[39;49mchunk_size, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n",
      "\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n",
      "\u001b[1;32m    900\u001b[0m     dialect,\n",
      "\u001b[1;32m    901\u001b[0m     delimiter,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n",
      "\u001b[1;32m    909\u001b[0m )\n",
      "\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n",
      "\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n",
      "\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n",
      "\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n",
      "\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n",
      "\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n",
      "\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n",
      "\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n",
      "\u001b[1;32m   1662\u001b[0m     f,\n",
      "\u001b[1;32m   1663\u001b[0m     mode,\n",
      "\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n",
      "\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n",
      "\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n",
      "\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n",
      "\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n",
      "\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n",
      "\u001b[1;32m   1670\u001b[0m )\n",
      "\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n",
      "\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n",
      "\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n",
      "\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n",
      "\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n",
      "\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n",
      "\u001b[1;32m    860\u001b[0m             handle,\n",
      "\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n",
      "\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n",
      "\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n",
      "\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n",
      "\u001b[1;32m    865\u001b[0m         )\n",
      "\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n",
      "\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/cell_barcde_labels.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define chunk size\n",
    "chunk_size = 500  # Adjust based on memory constraints\n",
    "\n",
    "# Read and process data in chunks\n",
    "obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method(copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_coo.py:403\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    402\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[0;32m--> 403\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[1;32m    405\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[1;32m    406\u001b[0m           indptr, indices, data)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_sputils.py:53\u001b[0m, in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (args,))\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchunk number \u001b[39m\u001b[39m{\u001b[39;00mchunk_counter\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# 2. Convert the chunk to a sparse matrix and store\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         sparse_chunk \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mcsr_matrix(chunk\u001b[39m.\u001b[39;49mvalues)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         sparse_matrices\u001b[39m.\u001b[39mappend(sparse_chunk)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# 3. Combine the sparse matrices vertically\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:84\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_matrix constructor usage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     86\u001b[0m     ))\n\u001b[1;32m     88\u001b[0m \u001b[39m# Read matrix dimensions given, if any\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:33\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     31\u001b[0m         arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     32\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39;49masformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat)\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(arg1)\n\u001b[1;32m     36\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg1, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_base.py:378\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method(copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_coo.py:403\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    401\u001b[0m indptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(M \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m    402\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(col, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[0;32m--> 403\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n\u001b[1;32m    405\u001b[0m coo_tocsr(M, N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz, row, col, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[1;32m    406\u001b[0m           indptr, indices, data)\n\u001b[1;32m    408\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_csr_container((data, indices, indptr), shape\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/scipy/sparse/_sputils.py:53\u001b[0m, in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     50\u001b[0m         _upcast_memo[\u001b[39mhash\u001b[39m(args)] \u001b[39m=\u001b[39m t\n\u001b[1;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m---> 53\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mno supported conversion for types: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (args,))\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 1024  # \n",
    "\n",
    "# Create an empty list to store sparse matrices from each chunk\n",
    "sparse_matrices = []\n",
    "genes = []\n",
    "chunk_counter = 0\n",
    "# 1. Read the CSV in chunks using a context manager\n",
    "with pd.read_csv(count_matrix_file_path, nrows=50) chunksize=chunk_size) as reader:\n",
    "    for chunk in reader:\n",
    "        chunk_counter += 1\n",
    "        print(f\"chunk number {chunk_counter}\")\n",
    "        # 2. get the genes\n",
    "        gene_chunk = chunk['gene']\n",
    "\n",
    "\n",
    "        \n",
    "        genes.append(gene_chunk)\n",
    "        # 3. Convert the chunk to a sparse matrix and store\n",
    "        sparse_chunk = scipy.sparse.csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)\n",
    "        sparse_matrices.append(sparse_chunk)\n",
    "\n",
    "\n",
    "# 3. Combine the sparse matrices vertically\n",
    "sparse_matrix = scipy.sparse.vstack(sparse_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_chunk = scipy.sparse.csr_matrix(chunk.iloc[:,1:].values, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40x713626 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 470307 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genes</th>\n",
       "      <th>MIR1302-2HG</th>\n",
       "      <th>FAM138A</th>\n",
       "      <th>OR4F5</th>\n",
       "      <th>AL627309.1</th>\n",
       "      <th>AL627309.3</th>\n",
       "      <th>AL627309.2</th>\n",
       "      <th>AL627309.5</th>\n",
       "      <th>AL627309.4</th>\n",
       "      <th>AP006222.2</th>\n",
       "      <th>AL732372.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GGCCTAATCGATTTAG-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAGTAACGTAGTCAAT-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAAAGCCAGCAGCTCA-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTCACCTCCTCCCTC-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTTCATCCAATCGCAC-1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "genes                 MIR1302-2HG  FAM138A  OR4F5  AL627309.1  AL627309.3   \n",
       "GGCCTAATCGATTTAG-1_1            0        0      0           0           0  \\\n",
       "TAGTAACGTAGTCAAT-1_1            0        0      0           0           0   \n",
       "GAAAGCCAGCAGCTCA-1_1            0        0      0           0           0   \n",
       "ACTCACCTCCTCCCTC-1_1            0        0      0           0           0   \n",
       "CTTCATCCAATCGCAC-1_1            0        0      0           0           0   \n",
       "\n",
       "genes                 AL627309.2  AL627309.5  AL627309.4  AP006222.2   \n",
       "GGCCTAATCGATTTAG-1_1           0           0           0           0  \\\n",
       "TAGTAACGTAGTCAAT-1_1           0           0           0           0   \n",
       "GAAAGCCAGCAGCTCA-1_1           0           0           0           0   \n",
       "ACTCACCTCCTCCCTC-1_1           0           0           0           0   \n",
       "CTTCATCCAATCGCAC-1_1           0           0           0           0   \n",
       "\n",
       "genes                 AL732372.1  \n",
       "GGCCTAATCGATTTAG-1_1           0  \n",
       "TAGTAACGTAGTCAAT-1_1           0  \n",
       "GAAAGCCAGCAGCTCA-1_1           0  \n",
       "ACTCACCTCCTCCCTC-1_1           0  \n",
       "CTTCATCCAATCGCAC-1_1           0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n",
    "obs_chunk = obs_iter.get_chunk()\n",
    "\n",
    "obs_ = pd.read_csv(obs_file_path,index_col=0)\n",
    "\n",
    "\n",
    "tmp = csr_matrix(count_chunk.values)\n",
    "var_ = pd.DataFrame(index=count_chunk.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((713626, 10), (713626, 3), (10, 0))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_chunk.shape, obs_.shape, var_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_chunk.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713626, 10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_chunk.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5ad_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# first chunk test\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m adata_chunk \u001b[39m=\u001b[39m anndata\u001b[39m.\u001b[39mAnnData(X\u001b[39m=\u001b[39mcsr_matrix(count_matrix_chunk\u001b[39m.\u001b[39mvalues),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                                   obs\u001b[39m=\u001b[39mobs_,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                                   var\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mcount_matrix_chunk\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m adata_chunk\u001b[39m.\u001b[39mwrite(h5ad_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h5ad_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count_matrix_file_path = \"./data/brain_atlas_full_counts_table.csv\"\n",
    "h5ad_file_path = \"./data/output_data.h5ad\"\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 10  # Adjust based on memory constraints\n",
    "\n",
    "# Read and process data in chunks\n",
    "# obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n",
    "obs_ = pd.read_csv(obs_file_path,index_col=0)\n",
    "\n",
    "count_matrix_iter = pd.read_csv(count_matrix_file_path, chunksize=chunk_size, index_col=0)\n",
    "\n",
    "\n",
    "count_matrix_chunk = count_matrix_iter.get_chunk().T\n",
    "\n",
    "# first chunk test\n",
    "adata_chunk = anndata.AnnData(X=csr_matrix(count_matrix_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk.write(h5ad_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIR1302-2HG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAM138A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL627309.4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP006222.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL732372.1</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [MIR1302-2HG, FAM138A, OR4F5, AL627309.1, AL627309.3, AL627309.2, AL627309.5, AL627309.4, AP006222.2, AL732372.1]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_chunk.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# second chunk test\n",
    "count_matrix_chunk = count_matrix_iter.get_chunk().T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_chunk2 = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1755: FutureWarning: The AnnData.concatenate method is deprecated in favour of the anndata.concat function. Please use anndata.concat instead.\n",
      "\n",
      "See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  warnings.warn(\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/ergonyc/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:782: UserWarning: \n",
      "AnnData expects .var.index to contain strings, but got values like:\n",
      "    []\n",
      "\n",
      "    Inferred to be: empty\n",
      "\n",
      "  value_idx = self._prep_dim_index(value.index, attr)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m adata_chunk\u001b[39m.\u001b[39;49mconcatenate(adata_chunk2, index_unique\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/anndata/_core/anndata.py:1808\u001b[0m, in \u001b[0;36mAnnData.concatenate\u001b[0;34m(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas)\u001b[0m\n\u001b[1;32m   1799\u001b[0m pat \u001b[39m=\u001b[39m \u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(batch_categories)\u001b[39m}\u001b[39;00m\u001b[39m)$\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m out\u001b[39m.\u001b[39mvar \u001b[39m=\u001b[39m merge_dataframes(\n\u001b[1;32m   1801\u001b[0m     [a\u001b[39m.\u001b[39mvar \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m all_adatas],\n\u001b[1;32m   1802\u001b[0m     out\u001b[39m.\u001b[39mvar_names,\n\u001b[1;32m   1803\u001b[0m     partial(merge_outer, batch_keys\u001b[39m=\u001b[39mbatch_categories, merge\u001b[39m=\u001b[39mmerge_same),\n\u001b[1;32m   1804\u001b[0m )\n\u001b[1;32m   1805\u001b[0m out\u001b[39m.\u001b[39mvar \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mvar\u001b[39m.\u001b[39miloc[\n\u001b[1;32m   1806\u001b[0m     :,\n\u001b[1;32m   1807\u001b[0m     (\n\u001b[0;32m-> 1808\u001b[0m         out\u001b[39m.\u001b[39;49mvar\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39mextract(pat, expand\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1809\u001b[0m         \u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1810\u001b[0m         \u001b[39m.\u001b[39margsort(kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1811\u001b[0m     ),\n\u001b[1;32m   1812\u001b[0m ]\n\u001b[1;32m   1814\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "adata_chunk.concatenate(adata_chunk2, index_unique=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "if os.path.exists(h5ad_path):\n",
    "    adata_existing = anndata.read(h5ad_path)\n",
    "    adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "    adata_combined.write(h5ad_path)\n",
    "else:\n",
    "        \n",
    "\n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "\n",
    "        \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "        if os.path.exists(h5ad_path):\n",
    "            adata_existing = anndata.read(h5ad_path)\n",
    "            adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "            adata_combined.write(h5ad_path)\n",
    "        else:\n",
    "            adata_chunk.write(h5ad_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use the first chunk to create the HDF5 file (with overwrite mode 'w')\n",
    "first_chunk = True\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        count_matrix_chunk = count_matrix_iter.get_chunk()\n",
    "\n",
    "\n",
    "\n",
    "        adata_chunk = anndata.AnnData(X=csr_matrix(count_chunk.values),\n",
    "                                  obs=obs_chunk,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "\n",
    "        \"\"\"Appends the chunk of data to the existing .h5ad file.\"\"\"\n",
    "        if os.path.exists(h5ad_path):\n",
    "            adata_existing = anndata.read(h5ad_path)\n",
    "            adata_combined = adata_existing.concatenate(adata_chunk, index_unique=None)\n",
    "            adata_combined.write(h5ad_path)\n",
    "        else:\n",
    "            adata_chunk.write(h5ad_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if first_chunk:\n",
    "            count_matrix_chunk.to_hdf(hdf5_file_path, key='data', mode='w')\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            count_matrix_chunk.to_hdf(hdf5_file_path, key='data', mode='a', format='table', append=True)\n",
    "            \n",
    "\n",
    "\n",
    "        adata_chunk = anndata.AnnData(X=count_matrix_chunk.values,\n",
    "                                    obs=obs_chunk,\n",
    "                                    var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "        \n",
    "        # Append the chunk to the .h5ad file\n",
    "        append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "\n",
    "    except StopIteration:\n",
    "        break\n",
    "    # for obs_chunk, count_matrix_chunk in zip(obs_iter, count_matrix_iter):\n",
    "    # Create an AnnData object for the current chunk\n",
    "\n",
    "    \n",
    "        # Read the CSV in chunks\n",
    "    for chunk in pd.read_csv(csv_file_path, chunksize=chunksize):\n",
    "    if first_chunk:\n",
    "        chunk.to_hdf(hdf5_file_path, key='data', mode='w')\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        chunk.to_hdf(hdf5_file_path, key='data', mode='a', format='table', append=True)\n",
    "        \n",
    "    \n",
    "    tmp = count_matrix_chunk.values    \n",
    "\n",
    "    adata_chunk = anndata.AnnData(X=count_matrix_chunk.values,\n",
    "                                  obs=obs_chunk,\n",
    "                                  var=pd.DataFrame(index=count_matrix_chunk.columns))\n",
    "    \n",
    "    # Append the chunk to the .h5ad file\n",
    "    append_chunk_to_h5ad(adata_chunk, h5ad_file_path)\n",
    "    break\n",
    "print(f\"Data has been saved to {h5ad_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs_chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m obs_chunk\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obs_chunk' is not defined"
     ]
    }
   ],
   "source": [
    "obs_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/cell_barcde_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m chunk_size \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m  \u001b[39m# Adjust based on memory constraints\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read and process data in chunks\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ergonyc/Projects/SingleCell/labelator/test_0.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m obs_iter \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(obs_file_path, chunksize\u001b[39m=\u001b[39;49mchunk_size, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/scverse10/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/cell_barcde_labels.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define chunk size\n",
    "chunk_size = 500  # Adjust based on memory constraints\n",
    "\n",
    "# Read and process data in chunks\n",
    "obs_iter = pd.read_csv(obs_file_path, chunksize=chunk_size, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scverse10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
