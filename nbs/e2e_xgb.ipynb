{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-welsh",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prototype end to end Labelator E2E_LBL8R \n",
    "\n",
    "### overview.\n",
    "This notebook protypes a \"labelator\".  The purpose of a \"labelator\" is to easily classify _cell types_ for out-of-sample \"Test\" data. \n",
    "\n",
    "Currently we are prototyping with several `anndata` _dataloaders_.  `scvi-tools`, `scarches`, and `anndata` each have an implimenation of a `torch` _dataloader_.   The `scarches` flavor seems to be a good middle ground and then DO have an SCVI implimentation.    Probably will use the _native_ loader for each type, but an `scarches` variant for our simpler models. \n",
    "\n",
    "To state our confirmation bias, it impliments the SCVI models which we like.\n",
    "\n",
    "We will validate potential models and calibrate them with simple expectations using a typical \"Train\"/\"Validate\" and \"Test\"/\"Probe\" approach.  \n",
    "\n",
    "\n",
    "Definitions:\n",
    "- \"Train\": data samples on which the model being tested is trained.  The `torch lightning` framework used by `scvi-tools` semi-automatically will \"validate\" to test out-of-sample prediction fidelity during training.\n",
    "- \"Test\": held-out samples to test the fidelity of the model.  \n",
    "- \"Probe\": data generated externally,which is _probing_ the fidelity of the model to general scRNAseq data.\n",
    "\n",
    "\n",
    "\n",
    "#### end-to-end\n",
    "We can also try some _end-to-end_ approaches where a single model takes us from raw counts to category probabilities.\n",
    "- __naive__\n",
    "    - boosted trees (e.g. xgboost)\n",
    "    - cVAE\n",
    "    - trVAE\n",
    "- __transfer__\n",
    "    - scANVI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Caveats\n",
    "There are several gotchas to anticipate:\n",
    "- features.  Currently we are locked into the 3k genes we are testing with.  Handling subsets and supersets is TBC.\n",
    "- batch.  In principle each \"embedding\" or decode part of the model should be able to measure a \"batch-correction\" parameter explicitly.  in scVI this is explicitly _learned_.  However in _naive_ inference mode it should just be an inferred fudge factor.\n",
    "- noise.  including or not including `doublet`, `mito`, or `ribo` metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### List of models\n",
    "\n",
    "e2e xgb variants:\n",
    "- raw counts: n=3000 features\n",
    "- normalized counts (scVI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f82e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    !pip uninstall -y typing_extensions\n",
    "    !pip install --quiet scvi-colab\n",
    "    from scvi_colab import install\n",
    "    install()\n",
    "\n",
    "else:\n",
    "    import os\n",
    "    # os.chdir('../')\n",
    "\n",
    "    ### import local python functions in ../lbl8r\n",
    "    sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "#### \n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import scvi\n",
    "from pathlib import Path\n",
    "# import scarches as sca\n",
    "\n",
    "from lbl8r.utils import make_pc_loading_adata\n",
    "from lbl8r.xgb import get_xgb_data, train_xgboost, test_xgboost\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65832e",
   "metadata": {},
   "source": [
    "### Load Train, Validate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5abafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    root_path = Path(\"/content/drive/MyDrive/\")\n",
    "    data_path = root_path / \"SingleCellModel/data\"\n",
    "else:\n",
    "    root_path = Path(\"../\")\n",
    "    if sys.platform == \"darwin\":\n",
    "        data_path = root_path / \"data/xylena_raw\"\n",
    "    else:\n",
    "        data_path = root_path / \"data/scdata/xylena\"\n",
    "        raw_data_path = root_path / \"data/scdata/xylena_raw\"\n",
    "\n",
    "XYLENA_ANNDATA = \"brain_atlas_anndata.h5ad\"\n",
    "XYLENA_METADATA = \"final_metadata.csv\"\n",
    "XYLENA_ANNDATA2 = \"brain_atlas_anndata_updated.h5ad\"\n",
    "\n",
    "XYLENA_TRAIN = XYLENA_ANNDATA.replace(\".h5ad\", \"_train_cnt.h5ad\")\n",
    "XYLENA_TEST = XYLENA_ANNDATA.replace(\".h5ad\", \"_test_cnt.h5ad\")\n",
    "\n",
    "XYLENA_TRAIN_SPARSE = XYLENA_TRAIN.replace(\".h5ad\", \"_sparse.h5ad\")\n",
    "XYLENA_TEST_SPARSE = XYLENA_TEST.replace(\".h5ad\", \"_sparse.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-lindsay",
   "metadata": {},
   "source": [
    "## model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167cfdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = root_path / \"e2e_models\"\n",
    "if not model_path.exists():\n",
    "    model_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38b710",
   "metadata": {},
   "source": [
    "## Raw Counts\n",
    "\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab35c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilen = data_path / XYLENA_TRAIN\n",
    "train_ad = ad.read_h5ad(outfilen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d928",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0d00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-mlogloss:1.05535\n",
      "[10]\tvalid-mlogloss:0.10354\n",
      "[20]\tvalid-mlogloss:0.06677\n",
      "[30]\tvalid-mlogloss:0.06383\n",
      "[40]\tvalid-mlogloss:0.06369\n",
      "[43]\tvalid-mlogloss:0.06375\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, label_encoder = get_xgb_data(train_ad)\n",
    "\n",
    "bst = train_xgboost(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18722c1d",
   "metadata": {},
   "source": [
    "### test and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602b4337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Astro       0.99      0.99      0.99     18646\n",
      "         ExN       0.98      0.99      0.98     50541\n",
      "         InN       0.98      0.99      0.99     25488\n",
      "          MG       1.00      0.99      0.99     11052\n",
      "         OPC       0.99      0.97      0.98     12809\n",
      "       Oligo       0.99      0.99      0.99     86666\n",
      "          VC       0.98      0.95      0.97      2524\n",
      "\n",
      "    accuracy                           0.99    207726\n",
      "   macro avg       0.99      0.98      0.98    207726\n",
      "weighted avg       0.99      0.99      0.99    207726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergonyc/mambaforge/envs/scverse11/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [00:48:48] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "outfilen = data_path / XYLENA_TEST\n",
    "test_ad = ad.read_h5ad(outfilen)\n",
    "\n",
    "test_xgboost(bst, test_ad, label_encoder)\n",
    "\n",
    "# Save the model for later use\n",
    "bst.save_model(model_path / \"xgb_raw_cnt.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2c44c",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## scVI normalized counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f50ba3",
   "metadata": {},
   "source": [
    "\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77936fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 502085 × 3000\n",
       "    obs: 'seurat_clusters', 'cell_type', 'sample', 'doublet_score', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'percent.rb', 'batch', 'sample_other', 'S.Score', 'G2M.Score', 'Phase', 'RNA_snn_res.0.3', 'seurat_clusters_other', 'ExN1', 'InN2', 'MG3', 'Astro4', 'Oligo5', 'OPC6', 'VC7', 'type', 'UMAP_1', 'UMAP_2', 'clean', 'test', 'train', 'tmp', '_scvi_batch', '_scvi_labels'\n",
       "    var: 'feat'\n",
       "    uns: 'pca'\n",
       "    obsm: 'X_pca', 'X_scVI', '_X_pca'\n",
       "    varm: 'PCs', '_PCs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path = data_path / \"LBL8R\"\n",
    "\n",
    "\n",
    "filen = out_path / XYLENA_TRAIN.replace(\"_cnt.h5ad\", \"_exp_nb_out.h5ad\")\n",
    "train_ad = ad.read_h5ad(filen)\n",
    "train_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf6dcf",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12b5d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-mlogloss:1.04261\n",
      "[10]\tvalid-mlogloss:0.09671\n",
      "[20]\tvalid-mlogloss:0.06358\n",
      "[30]\tvalid-mlogloss:0.06160\n",
      "[40]\tvalid-mlogloss:0.06166\n",
      "[46]\tvalid-mlogloss:0.06178\n"
     ]
    }
   ],
   "source": [
    "def preprocess_norm_cnts(X):\n",
    "    # no idea what works best... i suppose something\n",
    "    # X = 1e-2 * X\n",
    "    return np.log1p(X)\n",
    "\n",
    "\n",
    "X_train, y_train, label_encoder = get_xgb_data(train_ad)\n",
    "\n",
    "\n",
    "# X_train = preprocess_norm_cnts(X_train)\n",
    "\n",
    "bst = train_xgboost(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee62ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b546c2ae",
   "metadata": {},
   "source": [
    "### test and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f0b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Astro       0.99      0.99      0.99     18646\n",
      "         ExN       0.98      0.99      0.98     50541\n",
      "         InN       0.98      0.99      0.99     25488\n",
      "          MG       1.00      0.99      0.99     11052\n",
      "         OPC       0.99      0.97      0.98     12809\n",
      "       Oligo       0.99      0.99      0.99     86666\n",
      "          VC       0.98      0.95      0.97      2524\n",
      "\n",
      "    accuracy                           0.99    207726\n",
      "   macro avg       0.99      0.98      0.98    207726\n",
      "weighted avg       0.99      0.99      0.99    207726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergonyc/mambaforge/envs/scverse11/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [00:51:08] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "filen = out_path / XYLENA_TEST.replace(\"_cnt.h5ad\", \"_exp_nb_out.h5ad\")\n",
    "test_ad = ad.read_h5ad(filen)\n",
    "\n",
    "\n",
    "# TODO:  add preprocess/scaling?\n",
    "# X_train = preprocess_norm_cnts(X_train)\n",
    "\n",
    "\n",
    "test_xgboost(bst, test_ad, label_encoder)\n",
    "\n",
    "# Save the model for later use\n",
    "bst.save_model(model_path / \"xgb_scVInorm_cnt.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bb1bc",
   "metadata": {},
   "source": [
    "------------------\n",
    "TODO:  evaluation for entropy of predictions\n",
    "\n",
    "\n",
    "TODO:  strategy for \"Unknown\" low-quality predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
